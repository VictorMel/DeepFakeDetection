{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DeepFake Video Detection\n",
    "\n",
    "# <a id='0'>Content</a>\n",
    "\n",
    "- <a href='#1'>Introduction</a>  \n",
    "- <a href='#2'>Preliminary data exploration</a>  \n",
    "    * Load the packages  \n",
    "    * Load the data  \n",
    "    * Check files type  \n",
    "- <a href='#3'>Meta data exploration</a>  \n",
    "     * Missing data   \n",
    "     * Unique values  \n",
    "     * Most frequent originals  \n",
    "- <a href='#4'>Video data exploration</a>  \n",
    "     * Missing video (or meta) data  \n",
    "     * Few fake videos  \n",
    "     * Few real videos  \n",
    "     * Videos with same original  \n",
    "     * Test video files  \n",
    "     * Play video files\n",
    "- <a href='#5'>Face detection</a>  \n",
    "- <a href='#6'>Resources</a> \n",
    "- <a href='#7'>References</a>     \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "**DeepFake**, derived from \"Deep Learning\" and \"Fake,\" refers to the technology of taking one person's likeness from an image or video  \n",
    "and replacing it with another's using Deep Artificial Neural Networks. Major companies invest heavily in combating DeepFakes to counter  \n",
    "this threat. DeepFake is rapidly invading the film industry and threatens to compromise news agencies. Large digital companies, including  \n",
    "content providers and social platforms, are at the forefront of fighting DeepFakes. GANs (Generative Adversarial Networks) that generate  \n",
    "DeepFakes are improving daily. \n",
    "\n",
    "In the **Data Exploration** section, we perform a partial Exploratory Data Analysis (EDA) on the training and testing data. After checking  \n",
    "the file types, we focus first on the **metadata** files, exploring them in detail after importing them into dataframes. We then explore  \n",
    "video files by examining a sample of fake videos followed by real videos. Additionally, we analyze a few videos with the same origin, visualizing  \n",
    "one frame from both real and fake videos and playing a few videos. \n",
    "\n",
    "Next, we perform face (and other objects from the persons in the videos) extraction using OpenCV Haar Cascade resources to identify frontal faces,  \n",
    "eyes, smiles, and profile faces from still images in the videos.\n",
    "\n",
    "**Important Note**: The data analyzed here is just a small sample. The competition specifies that the training data is provided in archived chunks.  \n",
    "Models should be trained offline using the archived data provided by Kaggle. Models should then be loaded (max 1GB memory) into a Kernel for  \n",
    "inference, and predictions should be prepared as an output file from the Kernel.  \n",
    "\n",
    "In the **Resources** section, There is a short list of various resources for GAN and DeepFake, including blog  \n",
    "posts, Kaggle Kernels, and GitHub repositories."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='2'>Preliminary data exploration</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datasets:\n",
    "There are 4 groups of datasets associated with this competition.\n",
    "\n",
    "1. **Training Set: This dataset containing labels for the target.**  \n",
    "2. **Public Validation Set:** We trained our data using a small set of 400 videos/ids contained within this Public Validation Set.  \n",
    "This is available on the Kaggle Data page as test_videos.zip  \n",
    "3. **Public Test Set:**   \n",
    "Our code is running this on Public Test Set. When the re-run is complete, the score will be displayed.  \n",
    "4. **Private Test Set:**\n",
    "This dataset is privately held outside of Kaggle’s platform, and is used to compute the private leaderboard. It contains videos  \n",
    "with a similar format/nature as the Training & Public Validation/Test Sets, but are real, organic videos with and without deepfakes.  \n",
    "\n",
    "### Workflow:\n",
    "add more about the workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Evaluation**\n",
    "$LogLoss = -\\frac{1}{n} \\sum_{1=1}^{n} \\left[ y_{i} \\log \\left( \\hat{y}_{i} \\right) + \\left(1 - y_{i}\\right) \\log \\left(1 - \\hat{y}_{i} \\right) \\right] \\ $\n",
    "\n",
    "where\n",
    "\n",
    "* $n$ is the number of videos being predicted\n",
    "* $\\hat{y}_{i}$ is the predicted probability of the video being FAKE\n",
    "* $y_{i}$ is 1 if the video is FAKE, 0 if REAL\n",
    "* $\\log( )$ is the natural (base e) logarithm = $\\ln(  )$\n",
    "\n",
    "A smaller log loss is better. The use of the logarithm provides extreme punishments for being both confident and wrong.  \n",
    "In the worst possible case, a prediction that something is true when it is actually false will add infinite to your error score.  \n",
    "In order to prevent this, predictions are bounded away from the extremes by a small value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import os\n",
    "import sys\n",
    "import matplotlib \n",
    "import seaborn as sns \n",
    "import matplotlib.pyplot as plt \n",
    "from typing import Optional\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm_notebook \n",
    "import cv2 as cv \n",
    "import platform\n",
    "import subprocess\n",
    "import pyopencl as cl \n",
    "import tensorflow as tf\n",
    "import getpass\n",
    "import json\n",
    "from rocm.configure import * \n",
    "from utils.video_dataset import *\n",
    "\n",
    "from IPython.display import HTML\n",
    "from base64 import b64encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.10.1\n",
      "3.9.19 | packaged by conda-forge | (main, Mar 20 2024, 12:38:46) [MSC v.1929 64 bit (AMD64)]\n",
      "Kernel mode driver status: \n"
     ]
    }
   ],
   "source": [
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "print(sys.version)\n",
    "print(f'Kernel mode driver status: {subprocess.run(\"dkms status\", shell=True, capture_output=True, text=True).stdout}' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATASET\n",
    "DATA_CONFIG = './configs/data_path.json'\n",
    "\n",
    "with open(DATA_CONFIG, 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "DATA_FOLDER = data['data path'][getpass.getuser()][0]\n",
    "COMPRESSED_DATA_FOLDER = data['data path'][getpass.getuser()][1]\n",
    "BATCH_SIZE = data['batch size']\n",
    "DATA_DIRECTORIES = os.listdir(DATA_FOLDER)\n",
    "\n",
    "\n",
    "DATA_SAMPLE_FOLDER = '../input/deepfake-detection'\n",
    "TRAIN_SAMPLE_FOLDER = 'train_sample_videos'\n",
    "TEST_FOLDER = 'test_videos'\n",
    "\n",
    "# LIBS\n",
    "FACE_DETECTION_FOLDER = '../input/haar-cascades-for-face-detection'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UTILITY FUNCTIONS\n",
    "\n",
    "# Function to display video\n",
    "def play_video(video_file, subset=TRAIN_SAMPLE_FOLDER):\n",
    "    '''\n",
    "    Display video\n",
    "    param: video_file - the name of the video file to display\n",
    "    param: subset - the folder where the video file is located (can be TRAIN_SAMPLE_FOLDER or TEST_Folder)\n",
    "    '''\n",
    "    video_url = open(os.path.join(DATA_SAMPLE_FOLDER, subset,video_file),'rb').read()\n",
    "    data_url = f\"data:video/mp4;base64,{b64encode(video_url).decode()}\"\n",
    "    return HTML(f\"\"\"<video width=500 controls><source src=\"{data_url}\" type=\"video/mp4\"></video>\"\"\")\n",
    "\n",
    "# Function to display image from a video\n",
    "def display_image_from_video(video_path):\n",
    "    '''\n",
    "    input: video_path - path for video\n",
    "    process:\n",
    "    1. perform a video capture from the video\n",
    "    2. read the image\n",
    "    3. display the image\n",
    "    '''\n",
    "    capture_image = cv.VideoCapture(video_path) \n",
    "    ret, frame = capture_image.read()\n",
    "    fig = plt.figure(figsize=(10,10))\n",
    "    ax = fig.add_subplot(111)\n",
    "    frame = cv.cvtColor(frame, cv.COLOR_BGR2RGB)\n",
    "    ax.imshow(frame)\n",
    "# Function to get the OpenCL platform information\n",
    "def get_platform_info():\n",
    "    platforms = cl.get_platforms()\n",
    "    for platform in platforms:\n",
    "        devices = platform.get_devices()\n",
    "        print(f\"Platform Name: {platform.get_info(cl.platform_info.NAME)}\")\n",
    "        print(f\"Platform Vendor: {platform.get_info(cl.platform_info.VENDOR)}\")\n",
    "        print(f\"Platform Version: {platform.get_info(cl.platform_info.VERSION)}\")\n",
    "        print(f\"Platform Profile: {platform.get_info(cl.platform_info.PROFILE)}\")\n",
    "        for device in devices:\n",
    "            print(f\"Device: {device.name}\")\n",
    "\n",
    "    amd_platform = next(\n",
    "        (platform for platform in platforms if 'AMD' in platform.name), None\n",
    "    )\n",
    "\n",
    "# Function to check unique values in a dataset\n",
    "def unique_values(data):\n",
    "    total = data.count()\n",
    "    tt = pd.DataFrame(total)\n",
    "    tt.columns = ['Total']\n",
    "    uniques = []\n",
    "    for col in data.columns:\n",
    "        unique = data[col].nunique()\n",
    "        uniques.append(unique)\n",
    "    tt['Uniques'] = uniques\n",
    "    return(np.transpose(tt))\n",
    "\n",
    "# Function to check missing data in a dataset\n",
    "def missing_data(data):\n",
    "    total = data.isnull().sum()\n",
    "    percent = (data.isnull().sum()/data.isnull().count()*100)\n",
    "    tt = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\n",
    "    types = []\n",
    "    for col in data.columns:\n",
    "        dtype = str(data[col].dtype)\n",
    "        types.append(dtype)\n",
    "    tt['Types'] = types\n",
    "    return(np.transpose(tt))\n",
    "\n",
    "# Function to check the most frequent values in a dataset\n",
    "def most_frequent_values(data):\n",
    "    total = data.count()\n",
    "    tt = pd.DataFrame(total)\n",
    "    tt.columns = ['Total']\n",
    "    items = []\n",
    "    vals = []\n",
    "    for col in data.columns:\n",
    "        itm = data[col].value_counts().index[0]\n",
    "        val = data[col].value_counts().values[0]\n",
    "        items.append(itm)\n",
    "        vals.append(val)\n",
    "    tt['Most frequent item'] = items\n",
    "    tt['Frequency'] = vals\n",
    "    tt['Percent from total'] = np.round(vals / total * 100, 3)\n",
    "    return(np.transpose(tt))\n",
    "\n",
    "# Function to plot the count of classes in a dataset\n",
    "def plot_count(feature, title, df, size=1):\n",
    "    '''\n",
    "    Plot count of classes / feature\n",
    "    param: feature - the feature to analyze\n",
    "    param: title - title to add to the graph\n",
    "    param: df - dataframe from which we plot feature's classes distribution \n",
    "    param: size - default 1.\n",
    "    '''\n",
    "    f, ax = plt.subplots(1,1, figsize=(4*size,4))\n",
    "    total = float(len(df))\n",
    "    g = sns.countplot(x=feature, data=df, order=df[feature].value_counts().index[:20], palette='Set3', hue=feature, legend=False)\n",
    "    g.set_title(f\"Histogram of {title}\")\n",
    "    if(size > 2):\n",
    "        plt.xticks(rotation=90, size=8)\n",
    "    for p in ax.patches:\n",
    "        height = p.get_height()\n",
    "        ax.text(p.get_x()+p.get_width()/2.,\n",
    "                height + 3,\n",
    "                '{:1.2f}%'.format(100*height/total),\n",
    "                ha=\"center\")\n",
    "    plt.show()\n",
    "\n",
    "# Function read video metadata from json files\n",
    "def read_meta_from_json(data_directories, data_folder, compressed_data_folder):\n",
    "    \n",
    "    meta_df = pd.DataFrame()\n",
    "\n",
    "    for index, part_folder in enumerate(data_directories):\n",
    "        part_path = os.path.join(data_folder, part_folder)\n",
    "        json_file = next(file for file in os.listdir(part_path) if file.endswith('json'))\n",
    "        json_file_path = os.path.join(part_path, json_file)\n",
    "        \n",
    "        part_df = pd.read_json(json_file_path).T\n",
    "        part_df['part'] = index\n",
    "        part_df['path'] = part_path\n",
    "        part_df['path-compressed'] =  os.path.join(compressed_data_folder, os.path.basename(part_path))\n",
    "        part_df['filename'] = part_df.index\n",
    "        \n",
    "        meta_df = pd.concat([meta_df, part_df])\n",
    "\n",
    "    # Display 5 random rows from meta_df\n",
    "    display(meta_df.sample(n=5))\n",
    "    return meta_df\n",
    "\n",
    "# Function to display image from a video\n",
    "def display_image_from_video_list(video_path_list, video_folder=TRAIN_SAMPLE_FOLDER):\n",
    "    '''\n",
    "    input: video_path_list - path for video\n",
    "    process:\n",
    "    0. for each video in the video path list\n",
    "        1. perform a video capture from the video\n",
    "        2. read the image\n",
    "        3. display the image\n",
    "    '''\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots(2,3,figsize=(16,8))\n",
    "    # we only show images extracted from the first 6 videos\n",
    "    for i, video_file in enumerate(video_path_list[:6]):\n",
    "        video_path = os.path.join(DATA_SAMPLE_FOLDER, video_folder,video_file)\n",
    "        capture_image = cv.VideoCapture(video_path) \n",
    "        ret, frame = capture_image.read()\n",
    "        frame = cv.cvtColor(frame, cv.COLOR_BGR2RGB)\n",
    "        ax[i//3, i%3].imshow(frame)\n",
    "        ax[i//3, i%3].set_title(f\"Video: {video_file}\")\n",
    "        ax[i//3, i%3].axis('on')\n",
    "        \n",
    "# Function from moviepy.editor import AudioFileClip\n",
    "def LoadVideo(filepath, down_fps, scale_fact, isGray):\n",
    "    video = []\n",
    "    \n",
    "    # Open the video file\n",
    "    cap = cv.VideoCapture(filepath)\n",
    "    \n",
    "    # Get video properties\n",
    "    fps = cap.get(cv.CAP_PROP_FPS)  # Frames per second\n",
    "    fcnt = int(cap.get(cv.CAP_PROP_FRAME_COUNT))  # Total number of frames\n",
    "    fps_factor = round(fps / down_fps)  # Factor to downsample frames\n",
    "    \n",
    "    # Loop through each frame\n",
    "    for ii_f in range(fcnt):\n",
    "        if cap.isOpened() == False:\n",
    "            break\n",
    "        \n",
    "        # Read the next frame\n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        if (ii_f % fps_factor) != 0:  # Downsample frames\n",
    "            continue\n",
    "        \n",
    "        # Check if frame is read correctly\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        # Get frame dimensions and rotate if necessary\n",
    "        height, width, channels = frame.shape\n",
    "        if height > width:\n",
    "            frame = cv.rotate(frame, cv.ROTATE_90_CLOCKWISE)\n",
    "            height, width, channels = frame.shape\n",
    "        \n",
    "        # Calculate downscaled dimensions\n",
    "        down_width = round(width * scale_fact)\n",
    "        down_height = round(height * scale_fact)\n",
    "        down_points = (down_width, down_height)\n",
    "        \n",
    "        # Resize and convert frame to grayscale if specified\n",
    "        if isGray:\n",
    "            frame_sample = cv.resize(cv.cvtColor(frame, cv.COLOR_BGR2GRAY), down_points, interpolation=cv.INTER_LINEAR)\n",
    "        else:\n",
    "            frame_sample = cv.resize(cv.cvtColor(frame, cv.COLOR_BGR2RGB), down_points, interpolation=cv.INTER_LINEAR)\n",
    "        \n",
    "        # Append resized frame to video list\n",
    "        video.append(frame_sample)\n",
    "\n",
    "    # Release the video capture object and close all windows\n",
    "    cap.release()\n",
    "    cv.destroyAllWindows()\n",
    "    \n",
    "    # Convert video list to numpy array and then to torch tensor\n",
    "    video = np.array(video)\n",
    "    video = torch.tensor(video)\n",
    "    \n",
    "    return video"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add configurations for AMD GPU - Ubuntu only\n",
    "1. ADD rocm binary paths to the PATH environment variable.\n",
    "2. ADD open CL to LD_LIBRARY_PATH\n",
    "3. ADD user to \"render\" and \"video\" groups\n",
    "4. INSTALL clinfo\n",
    "5. INSTALL ocl-icd\n",
    "6. USE rocm-smi to check GPU's performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if platform.system() == 'Linux' and 'Ubuntu' in platform.version():\n",
    "    add_rocm_to_path()\n",
    "    add_ld_library_path()\n",
    "    check_user_in_groups()\n",
    "    install_clinfo()\n",
    "    install_ocl_icd()\n",
    "    rocm_smi()\n",
    "    clinfo()\n",
    "    rocminfo()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find physical devices (CPU and GPU)\n",
    "\n",
    "check that the cpu and gpu are recognized by tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n",
      "Num CPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "print(\"Num CPUs Available: \", len(tf.config.list_physical_devices('CPU')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Limit GPU resource to enable resources for casual work\n",
    "\n",
    "TensorFlow allocates all of the GPU’s memory by default, leaving nothing for the desktop environment and any  \n",
    "other apps to use. In order to solve this issue, we save some resources aside for casual workload and maintenance resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Platform Name: AMD Accelerated Parallel Processing\n",
      "Platform Vendor: Advanced Micro Devices, Inc.\n",
      "Platform Version: OpenCL 2.1 AMD-APP (3592.0)\n",
      "Platform Profile: FULL_PROFILE\n",
      "Device: gfx1100\n"
     ]
    }
   ],
   "source": [
    "if gpus := tf.config.experimental.list_physical_devices('GPU'):\n",
    "  try:\n",
    "    get_platform_info()\n",
    "    for gpu in gpus:\n",
    "      tf.config.experimental.set_memory_growth(gpu, True)\n",
    "  except RuntimeError as e:\n",
    "    print(e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train samples: 401\n",
      "Test samples: 400\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train samples: {len(os.listdir(os.path.join(DATA_SAMPLE_FOLDER, TRAIN_SAMPLE_FOLDER)))}\")\n",
    "print(f\"Test samples: {len(os.listdir(os.path.join(DATA_SAMPLE_FOLDER, TEST_FOLDER)))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also added a face detection resource."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Face detection resources: ['haarcascade_eye.xml', 'haarcascade_eye_tree_eyeglasses.xml', 'haarcascade_frontalface_alt.xml', 'haarcascade_frontalface_alt2.xml', 'haarcascade_frontalface_alt_tree.xml', 'haarcascade_frontalface_default.xml', 'haarcascade_fullbody.xml', 'haarcascade_profileface.xml', 'haarcascade_smile.xml', 'haarcascade_upperbody.xml']\n"
     ]
    }
   ],
   "source": [
    "print(f\"Face detection resources: {os.listdir(FACE_DETECTION_FOLDER)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check files type\n",
    "\n",
    "Here we check the train data files extensions. Most of the files looks to have `mp4` extension, let's check if there is other extension as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extensions: ['mp4', 'json']\n"
     ]
    }
   ],
   "source": [
    "train_list = list(os.listdir(os.path.join(DATA_SAMPLE_FOLDER, TRAIN_SAMPLE_FOLDER)))\n",
    "ext_dict = []\n",
    "for file in train_list:\n",
    "    file_ext = file.split('.')[1]\n",
    "    if (file_ext not in ext_dict):\n",
    "        ext_dict.append(file_ext)\n",
    "print(f\"Extensions: {ext_dict}\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's count how many files with each extensions there are.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files with extension `mp4`: 400\n",
      "Files with extension `json`: 1\n"
     ]
    }
   ],
   "source": [
    "for file_ext in ext_dict:\n",
    "    print(f\"Files with extension `{file_ext}`: {len([file for file in train_list if  file.endswith(file_ext)])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's repeat the same process for test videos folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extensions: ['mp4']\n",
      "Files with extension `mp4`: 400\n"
     ]
    }
   ],
   "source": [
    "test_list = list(os.listdir(os.path.join(DATA_SAMPLE_FOLDER, TEST_FOLDER)))\n",
    "ext_dict = []\n",
    "for file in test_list:\n",
    "    file_ext = file.split('.')[1]\n",
    "    if (file_ext not in ext_dict):\n",
    "        ext_dict.append(file_ext)\n",
    "print(f\"Extensions: {ext_dict}\")\n",
    "for file_ext in ext_dict:\n",
    "    print(f\"Files with extension `{file_ext}`: {len([file for file in train_list if  file.endswith(file_ext)])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the `json` file first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON file: metadata.json\n"
     ]
    }
   ],
   "source": [
    "json_file = [file for file in train_list if  file.endswith('json')][0]\n",
    "print(f\"JSON file: {json_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apparently here is a metadata file. Let's explore this JSON file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>split</th>\n",
       "      <th>original</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>aagfhgtpmv.mp4</th>\n",
       "      <td>FAKE</td>\n",
       "      <td>train</td>\n",
       "      <td>vudstovrck.mp4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aapnvogymq.mp4</th>\n",
       "      <td>FAKE</td>\n",
       "      <td>train</td>\n",
       "      <td>jdubbvfswz.mp4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abarnvbtwb.mp4</th>\n",
       "      <td>REAL</td>\n",
       "      <td>train</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abofeumbvv.mp4</th>\n",
       "      <td>FAKE</td>\n",
       "      <td>train</td>\n",
       "      <td>atvmxvwyns.mp4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abqwwspghj.mp4</th>\n",
       "      <td>FAKE</td>\n",
       "      <td>train</td>\n",
       "      <td>qzimuostzz.mp4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               label  split        original\n",
       "aagfhgtpmv.mp4  FAKE  train  vudstovrck.mp4\n",
       "aapnvogymq.mp4  FAKE  train  jdubbvfswz.mp4\n",
       "abarnvbtwb.mp4  REAL  train            None\n",
       "abofeumbvv.mp4  FAKE  train  atvmxvwyns.mp4\n",
       "abqwwspghj.mp4  FAKE  train  qzimuostzz.mp4"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_meta_from_json(path):\n",
    "    df = pd.read_json(os.path.join(DATA_FOLDER, path, json_file))\n",
    "    df = df.T\n",
    "    return df\n",
    "\n",
    "meta_train_df = get_meta_from_json(TRAIN_SAMPLE_FOLDER)\n",
    "meta_train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id=\"3\">Meta data exploration</a>\n",
    "\n",
    "Let's explore now the meta data in train sample. \n",
    "\n",
    "## Missing data\n",
    "\n",
    "We start by checking for any missing values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>split</th>\n",
       "      <th>original</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Total</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Percent</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Types</th>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          label   split original\n",
       "Total         0       0       77\n",
       "Percent     0.0     0.0    19.25\n",
       "Types    object  object   object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_data(meta_train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are missing data 19.25% of the samples (or 77). We suspect that actually the real data has missing original (if we generalize from the data we glimpsed). Let's check this hypothesis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>split</th>\n",
       "      <th>original</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Total</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Percent</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Types</th>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          label   split original\n",
       "Total         0       0       77\n",
       "Percent     0.0     0.0    100.0\n",
       "Types    object  object   object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_data(meta_train_df.loc[meta_train_df.label=='REAL'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indeed, all missing `original` data are the one associated with `REAL` label.  \n",
    "\n",
    "## Unique values;\n",
    "\n",
    "Let's check into more details the unique values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>split</th>\n",
       "      <th>original</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Total</th>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Uniques</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>209</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         label  split  original\n",
       "Total      400    400       323\n",
       "Uniques      2      1       209"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_values(meta_train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We observe that `original` label has the same pattern for uniques values. We know that we have 77 missing data (that's why total is only 323) and we observe that we do have 209 unique examples.  \n",
    "\n",
    "## Most frequent originals\n",
    "\n",
    "Let's look now to the most frequent originals uniques in train sample data.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>split</th>\n",
       "      <th>original</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Total</th>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Most frequent item</th>\n",
       "      <td>FAKE</td>\n",
       "      <td>train</td>\n",
       "      <td>atvmxvwyns.mp4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Frequency</th>\n",
       "      <td>323</td>\n",
       "      <td>400</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Percent from total</th>\n",
       "      <td>80.75</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.858</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    label  split        original\n",
       "Total                 400    400             323\n",
       "Most frequent item   FAKE  train  atvmxvwyns.mp4\n",
       "Frequency             323    400               6\n",
       "Percent from total  80.75  100.0           1.858"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_frequent_values(meta_train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that most frequent **label** is `FAKE` (80.75%), `meawmsgiti.mp4` is the most frequent **original** (6 samples)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do now some data distribution visualizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_count('split', 'split (train)', meta_train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_count('label', 'label (train)', meta_train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the `REAL` are only 19.25% in train sample videos, with the `FAKE`s acounting for 80.75% of the samples. \n",
    "\n",
    "\n",
    "# <a id=\"4\">Video data exploration</a>\n",
    "\n",
    "\n",
    "In the following we will explore some of the video data. \n",
    "\n",
    "\n",
    "## Missing video (or meta) data\n",
    "\n",
    "We check first if the list of files in the meta info and the list from the folder are the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metadata: 400, Folder: 400\n",
      "Files in metadata and not in folder: 0\n",
      "Files in folder and not in metadata: 0\n"
     ]
    }
   ],
   "source": [
    "meta = np.array(list(meta_train_df.index))\n",
    "storage = np.array([file for file in train_list if  file.endswith('mp4')])\n",
    "print(f\"Metadata: {meta.shape[0]}, Folder: {storage.shape[0]}\")\n",
    "print(f\"Files in metadata and not in folder: {np.setdiff1d(meta,storage,assume_unique=False).shape[0]}\")\n",
    "print(f\"Files in folder and not in metadata: {np.setdiff1d(storage,meta,assume_unique=False).shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's visualize now the data.  \n",
    "\n",
    "We select first a list of fake videos.\n",
    "\n",
    "## Few fake videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['avgiuextiz.mp4', 'esxrvsgpvb.mp4', 'cdphtzqrvp.mp4']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fake_train_sample_video = list(meta_train_df.loc[meta_train_df.label=='FAKE'].sample(3).index)\n",
    "fake_train_sample_video"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From [4] ([Basic EDA Face Detection, split video, ROI](https://www.kaggle.com/marcovasquez/basic-eda-face-detection-split-video-roi)) we modified a function for displaying a selected image from a video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for video_file in fake_train_sample_video:\n",
    "#     display_image_from_video(os.path.join(DATA_SAMPLE_FOLDER, TRAIN_SAMPLE_FOLDER, video_file))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try now the same for few of the images that are real.  \n",
    "\n",
    "\n",
    "## Few real videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['clrycekyst.mp4', 'beboztfcme.mp4', 'bddjdhzfze.mp4']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real_train_sample_video = list(meta_train_df.loc[meta_train_df.label=='REAL'].sample(3).index)\n",
    "real_train_sample_video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for video_file in real_train_sample_video:\n",
    "#     display_image_from_video(os.path.join(DATA_SAMPLE_FOLDER, TRAIN_SAMPLE_FOLDER, video_file))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Videos with same original\n",
    "\n",
    "Let's look now to set of samples with the same original."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# meta_train_df['original'].value_counts()[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We pick one of the originals with largest number of samples.   \n",
    "\n",
    "We also modify our visualization function to work with multiple images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# same_original_fake_train_sample_video = list(meta_train_df.loc[meta_train_df.original=='meawmsgiti.mp4'].index)\n",
    "# display_image_from_video_list(same_original_fake_train_sample_video)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look now to a different selection of videos with the same original. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# same_original_fake_train_sample_video = list(meta_train_df.loc[meta_train_df.original=='atvmxvwyns.mp4'].index)\n",
    "# display_image_from_video_list(same_original_fake_train_sample_video)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# same_original_fake_train_sample_video = list(meta_train_df.loc[meta_train_df.original=='qeumxirsme.mp4'].index)\n",
    "# display_image_from_video_list(same_original_fake_train_sample_video)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    " # same_original_fake_train_sample_video = list(meta_train_df.loc[meta_train_df.original=='kgbkktcjxf.mp4'].index)\n",
    " # display_image_from_video_list(same_original_fake_train_sample_video)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test video files\n",
    "\n",
    "Let's also look to few of the test data files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_videos = pd.DataFrame(list(os.listdir(os.path.join(DATA_SAMPLE_FOLDER, TEST_FOLDER))), columns=['video'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_videos.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's visualize now one of the videos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display_image_from_video(os.path.join(DATA_SAMPLE_FOLDER, TEST_FOLDER, test_videos.iloc[0].video))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look to some more videos from test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display_image_from_video_list(test_videos.sample(6).video, TEST_FOLDER)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='5'>Face detection</a>  \n",
    "\n",
    "From [5] ([Face Detection using OpenCV](https://www.kaggle.com/serkanpeldek/face-detection-with-opencv)) by [@serkanpeldek](https://www.kaggle.com/serkanpeldek) we got and slightly modified the functions to extract face, profile face, eyes and smile.  \n",
    "\n",
    "The class ObjectDetector initialize the cascade classifier (using the imported resource). The function **detect** uses a method of the CascadeClassifier to detect objects into images - in this case the face, eye, smile or profile face."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ObjectDetector():\n",
    "    '''\n",
    "    Class for Object Detection\n",
    "    '''\n",
    "    \n",
    "    def __init__(self,object_cascade_path):\n",
    "        '''\n",
    "        param: object_cascade_path - path for the *.xml defining the parameters for {face, eye, smile, profile}\n",
    "        detection algorithm\n",
    "        source of the haarcascade resource is: https://github.com/opencv/opencv/tree/master/data/haarcascades\n",
    "        '''\n",
    "\n",
    "        self.objectCascade=cv.CascadeClassifier(object_cascade_path)\n",
    "\n",
    "\n",
    "    def detect(self, image, \n",
    "               scale_factor=1.3,\n",
    "               min_neighbors=5,\n",
    "               min_size=(20,20)):\n",
    "        '''\n",
    "        Function return rectangle coordinates of object for given image\n",
    "        param: image - image to process\n",
    "        param: scale_factor - scale factor used for object detection\n",
    "        param: min_neighbors - minimum number of parameters considered during object detection\n",
    "        param: min_size - minimum size of bounding box for object detected\n",
    "        '''\n",
    "        return self.objectCascade.detectMultiScale(\n",
    "            image,\n",
    "            scaleFactor=scale_factor,\n",
    "            minNeighbors=min_neighbors,\n",
    "            minSize=min_size,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We load the resources for frontal face, eye, smile and profile face detection.  \n",
    "\n",
    "Then we initialize the `ObjectDetector` objects defined above with the respective resources, to use CascadeClassifier for each specific task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Frontal face, profile, eye and smile  haar cascade loaded\n",
    "\n",
    "frontal_path = f\"{FACE_DETECTION_FOLDER}/haarcascade_frontalface_default.xml\"\n",
    "eye_path = f\"{FACE_DETECTION_FOLDER}/haarcascade_eye.xml\"\n",
    "profile_path = f\"{FACE_DETECTION_FOLDER}/haarcascade_profileface.xml\"\n",
    "smile_path = f\"{FACE_DETECTION_FOLDER}/haarcascade_smile.xml\"\n",
    "paths_list = [frontal_path, eye_path, profile_path, smile_path]\n",
    "\n",
    "#Detector object created\n",
    "front_d, eye_d, prof_d, smile_d = [ObjectDetector(path) for path in paths_list]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also define a function for detection and display of all these specific objects.  \n",
    "\n",
    "The function call the **detect** method of the **ObjectDetector** object. For each object we are using a different shape and color, as following:\n",
    "* Frontal face: green rectangle;  \n",
    "* Eye: red circle;  \n",
    "* Smile: red rectangle;  \n",
    "* Profile face: blue rectangle.  \n",
    "\n",
    "Note: due to a huge amount of false positive, we deactivate for now the smile detector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_objects(image, scale_factor, min_neighbors, min_size):\n",
    "    '''\n",
    "    Objects detection function\n",
    "    Identify frontal face, eyes, smile and profile face and display the detected objects over the image\n",
    "    param: image - the image extracted from the video\n",
    "    param: scale_factor - scale factor parameter for `detect` function of ObjectDetector object\n",
    "    param: min_neighbors - min neighbors parameter for `detect` function of ObjectDetector object\n",
    "    param: min_size - minimum size parameter for f`detect` function of ObjectDetector object\n",
    "    '''\n",
    "    \n",
    "    image_gray=cv.cvtColor(image, cv.COLOR_BGR2GRAY)\n",
    "\n",
    "\n",
    "    eyes=eye_d.detect(image_gray,\n",
    "                   scale_factor=scale_factor,\n",
    "                   min_neighbors=min_neighbors,\n",
    "                   min_size=(int(min_size[0]/2), int(min_size[1]/2)))\n",
    "\n",
    "    for x, y, w, h in eyes:\n",
    "        #detected eyes shown in color image\n",
    "        cv.circle(image,(int(x+w/2),int(y+h/2)),(int((w + h)/4)),(0, 0,255),3)\n",
    " \n",
    "    # deactivated due to many false positive\n",
    "    #smiles=smile_d.detect(image_gray,\n",
    "    #               scale_factor=scale_factor,\n",
    "    #               min_neighbors=min_neighbors,\n",
    "    #               min_size=(int(min_size[0]/2), int(min_size[1]/2)))\n",
    "\n",
    "    #for x, y, w, h in smiles:\n",
    "    #    #detected smiles shown in color image\n",
    "    #    cv.rectangle(image,(x,y),(x+w, y+h),(0, 0,255),3)\n",
    "\n",
    "\n",
    "    profiles=prof_d.detect(image_gray,\n",
    "                   scale_factor=scale_factor,\n",
    "                   min_neighbors=min_neighbors,\n",
    "                   min_size=min_size)\n",
    "\n",
    "    for x, y, w, h in profiles:\n",
    "        #detected profiles shown in color image\n",
    "        cv.rectangle(image,(x,y),(x+w, y+h),(255, 0,0),3)\n",
    "\n",
    "    faces=front_d.detect(image_gray,\n",
    "                   scale_factor=scale_factor,\n",
    "                   min_neighbors=min_neighbors,\n",
    "                   min_size=min_size)\n",
    "\n",
    "    for x, y, w, h in faces:\n",
    "        #detected faces shown in color image\n",
    "        cv.rectangle(image,(x,y),(x+w, y+h),(0, 255,0),3)\n",
    "\n",
    "    # image\n",
    "    fig = plt.figure(figsize=(10,10))\n",
    "    ax = fig.add_subplot(111)\n",
    "    image = cv.cvtColor(image, cv.COLOR_BGR2RGB)\n",
    "    ax.imshow(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function extracts an image from a video and then call the function that extracts the face rectangle from the image and display the rectangle above the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_image_objects(video_file, video_set_folder=TRAIN_SAMPLE_FOLDER):\n",
    "    '''\n",
    "    Extract one image from the video and then perform face/eyes/smile/profile detection on the image\n",
    "    param: video_file - the video from which to extract the image from which we extract the face\n",
    "    '''\n",
    "    video_path = os.path.join(DATA_FOLDER, video_set_folder,video_file)\n",
    "    capture_image = cv.VideoCapture(video_path) \n",
    "    ret, frame = capture_image.read()\n",
    "    #frame = cv.cvtColor(frame, cv.COLOR_BGR2RGB)\n",
    "    detect_objects(image=frame, scale_factor=1.3, min_neighbors=5, min_size=(50, 50))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We apply the function for face detection for a selection of images from train sample videos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# same_original_fake_train_sample_video = list(meta_train_df.loc[meta_train_df.original=='kgbkktcjxf.mp4'].index)\n",
    "# for video_file in same_original_fake_train_sample_video[1:4]:\n",
    "#     print(video_file)\n",
    "#     extract_image_objects(video_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_subsample_video = list(meta_train_df.sample(3).index)\n",
    "# for video_file in train_subsample_video:\n",
    "#     print(video_file)\n",
    "#     extract_image_objects(video_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look to a small collection of samples from test videos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subsample_test_videos = list(test_videos.sample(3).video)\n",
    "# for video_file in subsample_test_videos:\n",
    "#     print(video_file)\n",
    "#     extract_image_objects(video_file, TEST_FOLDER)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can observe that in some cases, when the subject is not looking frontally or when the luminosity is low, the algorithm for face detection is not detecting the face or eyes correctly. Due to a large amount of false positive, we deactivated for now the smile detector."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Play video files  \n",
    "\n",
    "From [Play video and processing](https://www.kaggle.com/hamditarek/play-video-and-processing) Kernel by [@hamditarek](https://www.kaggle.com/hamditarek) we learned how to play video files in a Kaggle Kernel.  \n",
    "Let's look to few fake videos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_videos = list(meta_train_df.loc[meta_train_df.label=='FAKE'].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# play_video(fake_videos[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# play_video(fake_videos[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# play_video(fake_videos[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# play_video(fake_videos[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# play_video(fake_videos[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# play_video(fake_videos[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# play_video(fake_videos[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# play_video(fake_videos[12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# play_video(fake_videos[15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# play_video(fake_videos[18])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From visual inspection of these fakes videos, in some cases is very easy to spot the anomalies created when engineering the deep fake, in some cases is more difficult."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(DATA_CONFIG, 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "DATA_FOLDER = data['data path'][getpass.getuser()][0]\n",
    "COMPRESSED_DATA_FOLDER = data['data path'][getpass.getuser()][1]\n",
    "BATCH_SIZE = data['batch size']\n",
    "DATA_DIRECTORIES = os.listdir(DATA_FOLDER)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read meta data into Pandas' DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>split</th>\n",
       "      <th>original</th>\n",
       "      <th>part</th>\n",
       "      <th>path</th>\n",
       "      <th>path-compressed</th>\n",
       "      <th>filename</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>qdjfbfqwau.mp4</th>\n",
       "      <td>FAKE</td>\n",
       "      <td>train</td>\n",
       "      <td>lkjgzcuaoi.mp4</td>\n",
       "      <td>4</td>\n",
       "      <td>F:\\dfdc\\dfdc_train_part_12</td>\n",
       "      <td>F:\\dfdc-comp\\dfdc_train_part_12</td>\n",
       "      <td>qdjfbfqwau.mp4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shenidieml.mp4</th>\n",
       "      <td>FAKE</td>\n",
       "      <td>train</td>\n",
       "      <td>abzkauwmbl.mp4</td>\n",
       "      <td>38</td>\n",
       "      <td>F:\\dfdc\\dfdc_train_part_43</td>\n",
       "      <td>F:\\dfdc-comp\\dfdc_train_part_43</td>\n",
       "      <td>shenidieml.mp4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pruskulhhm.mp4</th>\n",
       "      <td>FAKE</td>\n",
       "      <td>train</td>\n",
       "      <td>osyfcyjccv.mp4</td>\n",
       "      <td>39</td>\n",
       "      <td>F:\\dfdc\\dfdc_train_part_44</td>\n",
       "      <td>F:\\dfdc-comp\\dfdc_train_part_44</td>\n",
       "      <td>pruskulhhm.mp4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mkejzspdrg.mp4</th>\n",
       "      <td>FAKE</td>\n",
       "      <td>train</td>\n",
       "      <td>fpodzuuebt.mp4</td>\n",
       "      <td>27</td>\n",
       "      <td>F:\\dfdc\\dfdc_train_part_33</td>\n",
       "      <td>F:\\dfdc-comp\\dfdc_train_part_33</td>\n",
       "      <td>mkejzspdrg.mp4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ehrsmbkjtb.mp4</th>\n",
       "      <td>FAKE</td>\n",
       "      <td>train</td>\n",
       "      <td>bmrwcqrpyp.mp4</td>\n",
       "      <td>8</td>\n",
       "      <td>F:\\dfdc\\dfdc_train_part_16</td>\n",
       "      <td>F:\\dfdc-comp\\dfdc_train_part_16</td>\n",
       "      <td>ehrsmbkjtb.mp4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               label  split        original  part                        path  \\\n",
       "qdjfbfqwau.mp4  FAKE  train  lkjgzcuaoi.mp4     4  F:\\dfdc\\dfdc_train_part_12   \n",
       "shenidieml.mp4  FAKE  train  abzkauwmbl.mp4    38  F:\\dfdc\\dfdc_train_part_43   \n",
       "pruskulhhm.mp4  FAKE  train  osyfcyjccv.mp4    39  F:\\dfdc\\dfdc_train_part_44   \n",
       "mkejzspdrg.mp4  FAKE  train  fpodzuuebt.mp4    27  F:\\dfdc\\dfdc_train_part_33   \n",
       "ehrsmbkjtb.mp4  FAKE  train  bmrwcqrpyp.mp4     8  F:\\dfdc\\dfdc_train_part_16   \n",
       "\n",
       "                                path-compressed        filename  \n",
       "qdjfbfqwau.mp4  F:\\dfdc-comp\\dfdc_train_part_12  qdjfbfqwau.mp4  \n",
       "shenidieml.mp4  F:\\dfdc-comp\\dfdc_train_part_43  shenidieml.mp4  \n",
       "pruskulhhm.mp4  F:\\dfdc-comp\\dfdc_train_part_44  pruskulhhm.mp4  \n",
       "mkejzspdrg.mp4  F:\\dfdc-comp\\dfdc_train_part_33  mkejzspdrg.mp4  \n",
       "ehrsmbkjtb.mp4  F:\\dfdc-comp\\dfdc_train_part_16  ehrsmbkjtb.mp4  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "meta_df = read_meta_from_json(DATA_DIRECTORIES, DATA_FOLDER, COMPRESSED_DATA_FOLDER)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Total number of videos in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data samples: 119154\n"
     ]
    }
   ],
   "source": [
    "print(f\"Data samples: {len(meta_df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full data set exploration\n",
    "\n",
    "1. Histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZwAAAGHCAYAAACEUORhAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8fJSN1AAAACXBIWXMAAA9hAAAPYQGoP6dpAABAtUlEQVR4nO3deVxU9f4/8NfIMizCiCDgKLmkooRL4YaaoiaYopalJsnV65KGSShuZOaSgaJXKb1pGUnlgpWXtKsS6k2MAEUKDVNpQcGEoIBBEAHh8/vDH+frcQAB8bD4ej4e83g0n/M+53w+42lefM6cmaMSQggQERE9ZC0augNERPRoYOAQEZEiGDhERKQIBg4RESmCgUNERIpg4BARkSIYOEREpAgGDhERKYKBQ0REimDgUJ2FhYVBpVLh7NmzlS739PREx44dZW0dO3bEjBkzarWf2NhYrF69Gnl5eXXr6CNo//79eOKJJ2BqagqVSoWkpKRK606ePAmVSoWTJ0/Weh/3+/evi4ptXrlypUb1a9euhZOTE8rLywEAN2/exOrVq+s0npp4kNcrNzcXrVq1wldffVXv/WoqGDikqIiICKxcubJW68TGxmLNmjUMnBrKzs6Gt7c3Hn/8cURGRiIuLg7dunVr6G7Vu+vXryM4OBhr165FixZ33spu3ryJNWvWPLTAeeqppxAXF4ennnqq1utaWVlh4cKFWLJkCUpKSh5C7xo/Bg4p6sknn8Tjjz/e0N2oldLSUty+fbuhu1FjKSkpKC0txbRp0zBs2DAMHDgQZmZmDd2tevfuu++iVatWmDhxYp23cfPmzVrVW1paYuDAgbC0tKzT/ubNm4crV67gyy+/rNP6TR0DhxR17ym18vJyrFu3Do6OjjA1NUWrVq3Qq1cvvPvuuwCA1atXY8mSJQCATp06QaVSyU5plJeXIzg4GN27d4darYatrS3+8Y9/4Nq1a7L9CiEQGBiIDh06wMTEBH379sWxY8fg5uYGNzc3qa7ilMlnn30Gf39/tGvXDmq1Gr/++iuys7Ph4+MDJycntGzZEra2thgxYgS+++472b6uXLkClUqFjRs3YsOGDejYsSNMTU3h5uYmhcHy5cuh1Wqh0Wjw/PPPIysrq0av36FDh+Dq6gozMzNYWFhg1KhRiIuLk5bPmDEDQ4YMAQBMmTIFKpVKNr6aOHv2LF566SWp3x07dsTUqVNx9erVSutzc3Pxz3/+E61bt4a5uTnGjRuH33//Xa/u+PHjGDlyJCwtLWFmZobBgwfjxIkTtepbhZKSEoSGhsLLy0ua3Vy5cgVt2rQBAKxZs0Y6ViqOt9WrV0OlUuGHH37Aiy++CCsrK+mPn5qOubJTajNmzEDLli3x66+/YsyYMWjZsiUcHBzg7++P4uJi2fp2dnYYNWoUduzYUadxN3UMHHpgZWVluH37tt6jJj9EHhwcjNWrV2Pq1Kk4fPgw9u/fj1mzZkmnz2bPno0FCxYAAP7zn/8gLi5Odkrj1VdfxbJlyzBq1CgcOnQIb7/9NiIjIzFo0CD89ddf0n5WrFiBFStWYPTo0Th48CDmzZuH2bNnIyUlpdJ+BQQEIC0tDTt27MDXX38NW1tb5OTkAABWrVqFw4cPY9euXejcuTPc3NwqPYXz73//G99//z3+/e9/46OPPsKlS5cwbtw4zJo1C9nZ2fj4448RHByM48ePY/bs2fd9rfbu3YsJEybA0tIS+/btQ2hoKHJzc+Hm5oaYmBgAwMqVK/Hvf/8bABAYGIi4uDi8//7799323a5cuQJHR0eEhITgm2++wYYNG5CRkYF+/frJXtMKs2bNQosWLbB3716EhITgzJkzcHNzk50C3b17N9zd3WFpaYlPPvkEn3/+OVq3bg0PD486hc7p06fx999/Y/jw4VJb27ZtERkZKfWp4li59xTuxIkT0aVLF3zxxRfSG39tx3yv0tJSjB8/HiNHjsTBgwcxc+ZMbNmyBRs2bNCrdXNzw/fff/9oniIWRHW0a9cuAaDaR4cOHWTrdOjQQUyfPl167unpKfr06VPtfjZu3CgAiNTUVFn7xYsXBQDh4+Mjaz99+rQAIN544w0hhBA5OTlCrVaLKVOmyOri4uIEADFs2DCp7dtvvxUAxNChQ+87/tu3b4vS0lIxcuRI8fzzz0vtqampAoDo3bu3KCsrk9pDQkIEADF+/HjZdvz8/AQAodPpqtxXWVmZ0Gq1omfPnrJt3rhxQ9ja2opBgwbpjeGLL7647xgqar/99ttqx1lQUCDMzc3Fu+++K7VX/PvfPXYhhPj+++8FALFu3TohhBCFhYWidevWYty4cXpj6t27t+jfv7/eNu/9t77Xhg0bBACRmZkpa8/OzhYAxKpVq/TWWbVqlQAg3nrrrWq3Xd2YK3u9pk+fLgCIzz//XLaNMWPGCEdHR71tHzt2TAAQR48evW8/mhvOcOiBffrpp0hISNB7VJzaqU7//v1x7tw5+Pj44JtvvkF+fn6N9/vtt98CgN5Vb/3790ePHj2kv5zj4+NRXFyMyZMny+oGDhyodxVdhRdeeKHS9h07duCpp56CiYkJDA0NYWRkhBMnTuDixYt6tWPGjJFO9wBAjx49AABjx46V1VW0p6WlVTFS4PLly7h+/Tq8vb1l22zZsiVeeOEFxMfH1/rziKoUFBRg2bJl6NKlCwwNDWFoaIiWLVuisLCw0nG+/PLLsueDBg1Chw4dpH+f2NhY5OTkYPr06bIZcHl5OUaPHo2EhAQUFhbWqo/Xr1+HSqWCjY1NrcdX2b9tbcd8L5VKhXHjxsnaevXqVelpSFtbWwDAH3/8Ueu+N3WGDd0Bavp69OiBvn376rVrNBqkp6dXu25AQADMzc2xe/du7NixAwYGBhg6dCg2bNhQ6Tbv9vfffwO4cyrlXlqtVvqfvaLOzs5Or66ytqq2uXnzZvj7+2PevHl4++23YWNjAwMDA6xcubLSN6XWrVvLnhsbG1fbfuvWrUr7cvcYqhpreXk5cnNz6+XiAC8vL5w4cQIrV65Ev379YGlpCZVKhTFjxqCoqEiv3t7evtK2ij7/+eefAIAXX3yxyn3m5OTA3Ny8xn0sKiqCkZERDAwMarxOhcpew9qO+V5mZmYwMTGRtanV6kr/TSvqarLd5oaBQw3K0NAQixYtwqJFi5CXl4fjx4/jjTfegIeHB9LT06t9A7W2tgYAZGRkoH379rJl169fl/76raireOO7W2ZmZqWzHJVKpde2e/duuLm5Yfv27bL2GzduVD/IenD3WO91/fp1tGjRAlZWVg+8H51Oh//+979YtWoVli9fLrUXFxdLn2HdKzMzs9K2Ll26AID077B161YMHDiw0m1UFfxVsbGxQUlJCQoLC2sVVID+v21dxvwgKrZZl9lZU8dTatRotGrVCi+++CLmz5+PnJwc6ct/arUagP5fhCNGjABwJwjulpCQgIsXL2LkyJEAgAEDBkCtVmP//v2yuvj4+CqvvKqMSqWS+lLh/PnzsqvEHhZHR0e0a9cOe/fulV2MUVhYiAMHDkhXrj0olUoFIYTeOD/66COUlZVVus6ePXtkz2NjY3H16lXp6rjBgwejVatW+Pnnn9G3b99KHxWzvJrq3r07AOC3336TtVd1rFSnLmN+EBVX8Dk5OdX7ths7znCoQY0bNw7Ozs7o27cv2rRpg6tXryIkJAQdOnRA165dAQA9e/YEcOd7F9OnT4eRkREcHR3h6OiIV155BVu3bkWLFi3w7LPP4sqVK1i5ciUcHBywcOFCAHdOYS1atAhBQUGwsrLC888/j2vXrmHNmjVo27at7DOR6nh6euLtt9/GqlWrMGzYMFy+fBlr165Fp06dHvr3dFq0aIHg4GC8/PLL8PT0xNy5c1FcXIyNGzciLy8P69evr5f9WFpaYujQodi4cSNsbGzQsWNHREdHIzQ0FK1atap0nbNnz2L27NmYNGkS0tPTsWLFCrRr1w4+Pj4A7nzOtHXrVkyfPh05OTl48cUXYWtri+zsbJw7dw7Z2dl6s8b7qQiz+Ph49OrVS2q3sLBAhw4dcPDgQYwcORKtW7eWxlGfY34Q8fHxsLa2lo7rRwlnONSghg8fjlOnTmHevHkYNWoU3nzzTYwcORLR0dEwMjICcOfNJSAgAF9//TWGDBmCfv36ITExEQCwfft2rF+/HkeOHIGnpydWrFgBd3d3xMbGSqehAOCdd97BunXrcPjwYYwfPx7vvfcetm/fDltb2xq/qaxYsQL+/v4IDQ3F2LFj8dFHH2HHjh01ujiiPnh5eeGrr77C33//jSlTpuCf//wnLC0t8e2339ZrH/bu3Yvhw4dj6dKlmDhxIs6ePYtjx45Bo9FUWh8aGoqSkhK89NJL8PX1Rd++fXHy5EnZZ1XTpk3Dt99+i4KCAsydOxfPPPMMXn/9dfzwww/STLQ2HBwc8PTTT+PgwYOV9sfMzAzjx49Hv379sHr16nofc10JIXDo0CF4eXlVetq2uVMJUYMvSxA1Q6mpqejevTtWrVqFN954o6G7Q7V04MABTJkyBVevXkW7du0aujs1cuLECbi7u+PChQvSacFHCQOHHgnnzp3Dvn37MGjQIFhaWuLy5csIDg5Gfn4+kpOTa/2hNTU8IQQGDRoEFxcXbNu2raG7UyPDhw9Hly5dsHPnzobuSoPgZzj0SDA3N8fZs2cRGhqKvLw8aDQauLm54Z133mHYNFEqlQo7d+7EoUOHUF5eXuPP4hpKbm4uhg0bJn229SjiDIeIiBTRuP8kICKiZoOBQ0REimDgEBGRInjRgMLKy8tx/fp1WFhYPJLX4RNR8yOEwI0bN6DVaqu9eIOBo7Dr16/DwcGhobtBRFTv0tPT9X7X8G4MHIVZWFgAuPMPU9fb1BIRNSb5+flwcHCQ3t+qwsBRWMVpNEtLSwYOETUr9/uYgBcNEBGRIhg4RESkCAYOPbDbt2/jzTffRKdOnWBqaorOnTtj7dq1KC8vl2pWr16N7t27w9zcHFZWVnjmmWdw+vTpardbWlqKtWvX4vHHH4eJiQl69+6NyMhIWc327dvRq1cv6RSlq6srjh49KqvZtGkT7OzsYGdnhy1btsiWnT59Gi4uLg/lvidEdA9BitLpdAKA0Ol0Dd2VerNu3TphbW0t/vvf/4rU1FTxxRdfiJYtW4qQkBCpZs+ePeLYsWPit99+E8nJyWLWrFnC0tJSZGVlVbndpUuXCq1WKw4fPix+++038f777wsTExPxww8/SDWHDh0Shw8fFpcvXxaXL18Wb7zxhjAyMhLJyclCCCHOnz8vTE1NxYkTJ8Tx48eFiYmJ+Omnn4QQQpSUlIg+ffqIM2fOPKRXhujRUNP3NQaOwppj4IwdO1bMnDlT1jZx4kQxbdq0KtepeB2OHz9eZU3btm3Ftm3bZG0TJkwQL7/8crX9sbKyEh999JEQQoj9+/eLAQMGSMv69+8vPv/8cyGEEO+8847w9fWtdltEdH81fV/jKTV6YEOGDMGJEyeQkpIC4M6tAGJiYjBmzJhK60tKSvDhhx9Co9Ggd+/eVW63uLgYJiYmsjZTU1PExMRUWl9WVobw8HAUFhbC1dUVwJ27haakpCAtLQ1Xr15FSkoKnJ2d8euvvyIsLAzr1q2ry5CJqC4UCkD6/5rjDKe8vFwsX75cqFQqYWhoKFQqlQgMDNSr+/rrr4W5ublQqVRCq9Xe91TW1KlThZOTk0hJSRFlZWUiKipKmJqaCmNjY1nd+fPnhbm5uTAwMBAajUYcPnxYtnz79u2iW7duolu3bmL79u1CCCFGjhwpIiIixBdffCGeeOIJ0adPHxEdHf2ArwTRo4mn1Bqp5hg4+/btE+3btxf79u0T58+fF59++qlo3bq1CAsLk9UVFBSIX375RcTFxYmZM2eKjh07ij///LPK7WZlZYkJEyaIFi1aCAMDA9GtWzfh4+MjTE1NZXXFxcXil19+EQkJCWL58uXCxsZGXLhwocrt7tq1Szz33HMiMzNTaDQakZKSIv73v/+Jtm3bilu3bj3Yi0H0CGoSgRMdHS08PT1F27ZtBQAREREhW15eXi5WrVol2rZtK0xMTMSwYcOkD4Mr3Lp1S7z22mvC2tpamJmZiXHjxon09HRZTU5Ojpg2bZqwtLQUlpaWYtq0aSI3N1dWc/XqVeHp6SnMzMyEtbW1WLBggSguLpbVnD9/XgwdOlSYmJgIrVYr1qxZI8rLy2s15uYYOO3bt9f7rOXtt98Wjo6O1a7XpUuXSmdC9yoqKhLXrl0T5eXlYunSpcLJyana+pEjR4pXXnml0mXZ2dmiU6dOIj09XRw8eFD069dPWmZjYyPOnz9/3/4QkVyT+AynsLAQvXv3rvL2sMHBwdi8eTO2bduGhIQE2NvbY9SoUbhx44ZU4+fnh4iICISHhyMmJgYFBQXw9PSUXebq5eWFpKQkREZGIjIyEklJSfD29paWl5WVYezYsSgsLERMTAzCw8Nx4MAB+Pv7SzX5+fkYNWoUtFotEhISsHXrVmzatAmbN29+CK9M03Lz5k29H+wzMDCQXRZdGSEEiouL77t9ExMTtGvXDrdv38aBAwcwYcKEOm/Xz88PCxcuRPv27VFWVobS0lJp2e3bt3l5NNHDpEj81QDumeGUl5cLe3t7sX79eqnt1q1bQqPRiB07dgghhMjLyxNGRkYiPDxcqvnjjz9EixYtRGRkpBBCiJ9//lkAEPHx8VJNXFycACAuXbokhBDiyJEjokWLFuKPP/6Qavbt2yfUarWU2O+//77QaDSyUy5BQUFCq9VWO8u5deuW0Ol00iM9Pb3ZzXCmT58u2rVrJ10W/Z///EfY2NiIpUuXCiHunEoLCAgQcXFx4sqVKyIxMVHMmjVLqNVq2YzV29tbLF++XHoeHx8vDhw4IH777Tdx6tQpMWLECNGpUyfZ7DQgIECcOnVKpKamivPnz4s33nhDtGjRQkRFRen1MyoqSvTv31+UlZUJIYS4du2aMDExEUeOHBEffPCBsLa2Fjdv3nxIrxJR81XTGU6j/S211NRUZGZmwt3dXWpTq9UYNmwYYmNjMXfuXCQmJqK0tFRWo9Vq4ezsjNjYWHh4eCAuLg4ajQYDBgyQagYOHAiNRoPY2Fg4OjoiLi4Ozs7O0Gq1Uo2HhweKi4uRmJiI4cOHIy4uDsOGDYNarZbVBAQE4MqVK+jUqVOl4wgKCsKaNWvq7XXZnnCq3rZVX3rPeAlpxYX4x+xZuJGbC42NDfqOexbtJ7hje8IplBYX40hcDN7/aCcK83Qw11iig1N3vP7Buzh182+c+v9jir/wE6xzsqUxpiQlIXzDZvz1RwbUpqZ4YtAAzNm2Cft+OS/t+2TyOXwQtgv5f/0Nk5bmaNflccx/Nxi/tlLj17teq5JbxQicPQuzAlfhg8T/u8rthUUL8NK0aTA0NsKUFUsQlpyg0KtWM6/2G9rQXSCqN402cDIzMwEAdnZ2snY7OztcvXpVqjE2NoaVlZVeTcX6mZmZsLW11du+ra2trObe/VhZWcHY2FhW07FjR739VCyrKnACAgKwaNEi6XnFr6o2JybmZpi0aAEmLVpQ6XIjtRpzg+9/+fHCHe/Knnd7qg/e2v9ptet4r1xWoz4am6ix+svdeu2Dn/PE4Oc8a7QNInowjTZwKtz766NCiPv+Ium9NZXV10eNEKLKdSuo1WrZrIiI6FHVaL/4aW9vD+D/ZjoVsrKypJmFvb09SkpKkJubW23Nn3/+qbf97OxsWc29+8nNzUVpaWm1NVlZWQD0Z2FERKSv0QZOp06dYG9vj2PHjkltJSUliI6OxqBBgwAALi4uMDIyktVkZGQgOTlZqnF1dYVOp8OZM2ekmtOnT0On08lqkpOTkZGRIdVERUVBrVbDxcVFqjl16hRKSkpkNVqtVu9UGxER6WvQwCkoKEBSUhKSkpIA3LlQICkpCWlpaVCpVPDz80NgYCAiIiKQnJyMGTNmwMzMDF5eXgAAjUaDWbNmwd/fHydOnMCPP/6IadOmoWfPnnjmmWcAAD169MDo0aMxZ84cxMfHIz4+HnPmzIGnpyccHR0BAO7u7nBycoK3tzd+/PFHnDhxAosXL8acOXOkm6R5eXlBrVZjxowZSE5ORkREBAIDA7Fo0aL7nuIjIqIG/gzn7NmzGD58uPS84sP16dOnIywsDEuXLkVRURF8fHyQm5uLAQMGICoqSnYb0y1btsDQ0BCTJ09GUVERRo4cibCwMBgYGEg1e/bsga+vr3Q12/jx42Xf/TEwMMDhw4fh4+ODwYMHw9TUFF5eXti0aZNUo9FocOzYMcyfPx99+/aFlZUVFi1aJLsggIiIqqYSFZ98kyLy8/Oh0Wig0+nqdIvpxnhZND08vCyamoKavq812s9wiIioeWHgEBGRIhg4RESkCAYOEREpgoFDRESKYOAQEZEiGDhERKQIBg4RESmCgUNERIpg4BARkSIYOEREpAgGDhERKYKBQ0REimDgEBGRIhg4RESkCAYOEREpgoFDRESKYOAQEZEiGDhERKQIBg4RESmCgUNERIpg4BARkSIYOEREpAgGDhERKYKBQ0REimDgEBGRIhg4RESkCAYOEREpgoFDRESKYOAQEZEiGDhERKQIBg4RESmCgUNERIpg4BARkSIYOEREpAgGDhERKYKBQ0REimDgEBGRIhg4RESkCAYOEREpgoFDRESKYOAQEZEiGDhERKQIBg4RESmCgUNERIpg4BARkSIYOEREpIhGHTi3b9/Gm2++iU6dOsHU1BSdO3fG2rVrUV5eLtUIIbB69WpotVqYmprCzc0NFy5ckG2nuLgYCxYsgI2NDczNzTF+/Hhcu3ZNVpObmwtvb29oNBpoNBp4e3sjLy9PVpOWloZx48bB3NwcNjY28PX1RUlJyUMbPxFRc9KoA2fDhg3YsWMHtm3bhosXLyI4OBgbN27E1q1bpZrg4GBs3rwZ27ZtQ0JCAuzt7TFq1CjcuHFDqvHz80NERATCw8MRExODgoICeHp6oqysTKrx8vJCUlISIiMjERkZiaSkJHh7e0vLy8rKMHbsWBQWFiImJgbh4eE4cOAA/P39lXkxiIiaOJUQQjR0J6ri6ekJOzs7hIaGSm0vvPACzMzM8Nlnn0EIAa1WCz8/PyxbtgzAndmMnZ0dNmzYgLlz50Kn06FNmzb47LPPMGXKFADA9evX4eDggCNHjsDDwwMXL16Ek5MT4uPjMWDAAABAfHw8XF1dcenSJTg6OuLo0aPw9PREeno6tFotACA8PBwzZsxAVlYWLC0tazSm/Px8aDQa6HS6Gq9zt+0Jp2q9DjVdr/Yb2tBdILqvmr6vNeoZzpAhQ3DixAmkpKQAAM6dO4eYmBiMGTMGAJCamorMzEy4u7tL66jVagwbNgyxsbEAgMTERJSWlspqtFotnJ2dpZq4uDhoNBopbABg4MCB0Gg0shpnZ2cpbADAw8MDxcXFSExMrHIMxcXFyM/Plz2IiB5Fhg3dgeosW7YMOp0O3bt3h4GBAcrKyvDOO+9g6tSpAIDMzEwAgJ2dnWw9Ozs7XL16VaoxNjaGlZWVXk3F+pmZmbC1tdXbv62trazm3v1YWVnB2NhYqqlMUFAQ1qxZU5thExE1S416hrN//37s3r0be/fuxQ8//IBPPvkEmzZtwieffCKrU6lUsudCCL22e91bU1l9XWruFRAQAJ1OJz3S09Or7RcRUXPVqGc4S5YswfLly/HSSy8BAHr27ImrV68iKCgI06dPh729PYA7s4+2bdtK62VlZUmzEXt7e5SUlCA3N1c2y8nKysKgQYOkmj///FNv/9nZ2bLtnD59WrY8NzcXpaWlejOfu6nVaqjV6roMn4ioWWnUM5ybN2+iRQt5Fw0MDKTLojt16gR7e3scO3ZMWl5SUoLo6GgpTFxcXGBkZCSrycjIQHJyslTj6uoKnU6HM2fOSDWnT5+GTqeT1SQnJyMjI0OqiYqKglqthouLSz2PnIio+WnUM5xx48bhnXfewWOPPYYnnngCP/74IzZv3oyZM2cCuHOKy8/PD4GBgejatSu6du2KwMBAmJmZwcvLCwCg0Wgwa9Ys+Pv7w9raGq1bt8bixYvRs2dPPPPMMwCAHj16YPTo0ZgzZw4++OADAMArr7wCT09PODo6AgDc3d3h5OQEb29vbNy4ETk5OVi8eDHmzJlTp6vNiIgeNY06cLZu3YqVK1fCx8cHWVlZ0Gq1mDt3Lt566y2pZunSpSgqKoKPjw9yc3MxYMAAREVFwcLCQqrZsmULDA0NMXnyZBQVFWHkyJEICwuDgYGBVLNnzx74+vpKV7ONHz8e27Ztk5YbGBjg8OHD8PHxweDBg2FqagovLy9s2rRJgVeCiKjpa9Tfw2mO+D0cqg1+D4eagmbxPRwiImo+GDhERKQIBg4RESmCgUNERIpg4BARkSIYOEREpAgGDhERKYKBQ0REimDgEBGRIhg4RESkCAYOEREpgoFDRESKYOAQEZEiGDhERKQIBg4RESmCgUNERIpg4BARkSIYOEREpAgGDhERKYKBQ0REimDgEBGRIhg4RESkCAYOEREpgoFDRESKYOAQEZEiGDhERKQIBg4RESmCgUNERIpg4BARkSIYOEREpAgGDhERKYKBQ0REimDgEBGRIhg4RESkCAYOEREpgoFDRESKYOAQEZEiGDhERKQIBg4RESmCgUNERIpg4BARkSIYOEREpAgGDhERKYKBQ0REimDgEBGRIhg4RESkCAYOEREpgoFDRESKaPSB88cff2DatGmwtraGmZkZ+vTpg8TERGm5EAKrV6+GVquFqakp3NzccOHCBdk2iouLsWDBAtjY2MDc3Bzjx4/HtWvXZDW5ubnw9vaGRqOBRqOBt7c38vLyZDVpaWkYN24czM3NYWNjA19fX5SUlDy0sRMRNSeNOnByc3MxePBgGBkZ4ejRo/j555/xr3/9C61atZJqgoODsXnzZmzbtg0JCQmwt7fHqFGjcOPGDanGz88PERERCA8PR0xMDAoKCuDp6YmysjKpxsvLC0lJSYiMjERkZCSSkpLg7e0tLS8rK8PYsWNRWFiImJgYhIeH48CBA/D391fktSAiaupUQgjR0J2oyvLly/H999/ju+++q3S5EAJarRZ+fn5YtmwZgDuzGTs7O2zYsAFz586FTqdDmzZt8Nlnn2HKlCkAgOvXr8PBwQFHjhyBh4cHLl68CCcnJ8THx2PAgAEAgPj4eLi6uuLSpUtwdHTE0aNH4enpifT0dGi1WgBAeHg4ZsyYgaysLFhaWtZoTPn5+dBoNNDpdDVe527bE07Veh1qul7tN7Shu0B0XzV9X2vUM5xDhw6hb9++mDRpEmxtbfHkk09i586d0vLU1FRkZmbC3d1dalOr1Rg2bBhiY2MBAImJiSgtLZXVaLVaODs7SzVxcXHQaDRS2ADAwIEDodFoZDXOzs5S2ACAh4cHiouLZaf47lVcXIz8/HzZg4joUdSoA+f333/H9u3b0bVrV3zzzTeYN28efH198emnnwIAMjMzAQB2dnay9ezs7KRlmZmZMDY2hpWVVbU1tra2evu3tbWV1dy7HysrKxgbG0s1lQkKCpI+F9JoNHBwcKjNS0BE1Gw06sApLy/HU089hcDAQDz55JOYO3cu5syZg+3bt8vqVCqV7LkQQq/tXvfWVFZfl5p7BQQEQKfTSY/09PRq+0VE1Fw16sBp27YtnJycZG09evRAWloaAMDe3h4A9GYYWVlZ0mzE3t4eJSUlyM3Nrbbmzz//1Nt/dna2rObe/eTm5qK0tFRv5nM3tVoNS0tL2YOI6FHUqANn8ODBuHz5sqwtJSUFHTp0AAB06tQJ9vb2OHbsmLS8pKQE0dHRGDRoEADAxcUFRkZGspqMjAwkJydLNa6urtDpdDhz5oxUc/r0aeh0OllNcnIyMjIypJqoqCio1Wq4uLjU88iJiJofw4buQHUWLlyIQYMGITAwEJMnT8aZM2fw4Ycf4sMPPwRw5xSXn58fAgMD0bVrV3Tt2hWBgYEwMzODl5cXAECj0WDWrFnw9/eHtbU1WrdujcWLF6Nnz5545plnANyZNY0ePRpz5szBBx98AAB45ZVX4OnpCUdHRwCAu7s7nJyc4O3tjY0bNyInJweLFy/GnDlzOGshIqqBOs1wRowYofelSODOpXEjRox40D5J+vXrh4iICOzbtw/Ozs54++23ERISgpdfflmqWbp0Kfz8/ODj44O+ffvijz/+QFRUFCwsLKSaLVu24LnnnsPkyZMxePBgmJmZ4euvv4aBgYFUs2fPHvTs2RPu7u5wd3dHr1698Nlnn0nLDQwMcPjwYZiYmGDw4MGYPHkynnvuOWzatKnexktE1JzV6Xs4LVq0qPTKrqysLLRr1w6lpaX11sHmht/Dodrg93CoKajp+1qtTqmdP39e+u+ff/5Z9iF6WVkZIiMj0a5duzp0l4iImrtaBU6fPn2gUqmgUqkqPXVmamqKrVu31lvniIio+ahV4KSmpkIIgc6dO+PMmTNo06aNtMzY2Bi2trayz0WIiIgq1CpwKi5HLi8vfyidISKi5qvOl0WnpKTg5MmTyMrK0gugt95664E7RkREzUudAmfnzp149dVXYWNjA3t7e72ff2HgEBHRveoUOOvWrcM777wj3RKAiIjofur0xc/c3FxMmjSpvvtCRETNWJ0CZ9KkSYiKiqrvvhARUTNWp1NqXbp0wcqVKxEfH4+ePXvCyMhIttzX17deOkdERM1HnX7aplOnTlVvUKXC77///kCdas740zZUG/xpG2oKHspP21RITU2tc8eIiOjR1Kjvh0NERM1HnWY4M2fOrHb5xx9/XKfOEBFR81WnwLn3ds2lpaVITk5GXl5evd4Ph4iImo86BU5ERIReW3l5OXx8fNC5c+cH7hQRETU/9fYZTosWLbBw4UJs2bKlvjZJRETNSL1eNPDbb7/h9u3b9blJIiJqJup0Sm3RokWy50IIZGRk4PDhw5g+fXq9dIyIiJqXOgXOjz/+KHveokULtGnTBv/617/uewUbERE9muoUON9++21994OIiJq5Ot+ADQCys7Nx+fJlqFQqdOvWTXbLaSIiorvV6aKBwsJCzJw5E23btsXQoUPx9NNPQ6vVYtasWbh582Z995GIiJqBOgXOokWLEB0dja+//hp5eXnIy8vDwYMHER0dDX9///ruIxERNQN1OqV24MABfPnll3Bzc5PaxowZA1NTU0yePBnbt2+vr/4REVEzUacZzs2bN2FnZ6fXbmtry1NqRERUqToFjqurK1atWoVbt25JbUVFRVizZg1cXV3rrXNERNR81OmUWkhICJ599lm0b98evXv3hkqlQlJSEtRqNW89TURElapT4PTs2RO//PILdu/ejUuXLkEIgZdeegkvv/wyTE1N67uPRETUDNQpcIKCgmBnZ4c5c+bI2j/++GNkZ2dj2bJl9dI5IiJqPur0Gc4HH3yA7t2767U/8cQT2LFjxwN3ioiImp86BU5mZibatm2r196mTRtkZGQ8cKeIiKj5qVPgODg44Pvvv9dr//7776HVah+4U0RE1PzU6TOc2bNnw8/PD6WlpdItpU+cOIGlS5fylwaIiKhSdQqcpUuXIicnBz4+PigpKQEAmJiYYNmyZQgICKjXDhIRUfNQp8BRqVTYsGEDVq5ciYsXL8LU1BRdu3aFWq2u7/4REVEz8UC3J2jZsiX69etXX30hIqJmrE4XDRAREdUWA4eIiBTBwCEiIkUwcIiISBEMHCIiUgQDh4iIFMHAISIiRTBwiIhIEQwcIiJSBAOHiIgUwcAhIiJFNKnACQoKgkqlgp+fn9QmhMDq1auh1WphamoKNzc3XLhwQbZecXExFixYABsbG5ibm2P8+PG4du2arCY3Nxfe3t7QaDTQaDTw9vZGXl6erCYtLQ3jxo2Dubk5bGxs4OvrK/1aNhERVa/JBE5CQgI+/PBD9OrVS9YeHByMzZs3Y9u2bUhISIC9vT1GjRqFGzduSDV+fn6IiIhAeHg4YmJiUFBQAE9PT5SVlUk1Xl5eSEpKQmRkJCIjI5GUlARvb29peVlZGcaOHYvCwkLExMQgPDwcBw4c4P1/iIhqSCWEEA3difspKCjAU089hffffx/r1q1Dnz59EBISAiEEtFot/Pz8sGzZMgB3ZjN2dnbYsGED5s6dC51OhzZt2uCzzz7DlClTAADXr1+Hg4MDjhw5Ag8PD1y8eBFOTk6Ij4/HgAEDAADx8fFwdXXFpUuX4OjoiKNHj8LT0xPp6enSXU3Dw8MxY8YMZGVlwdLSstK+FxcXo7i4WHqen58PBwcH6HS6KtepzvaEU7Veh5quV/sNbeguEN1Xfn4+NBrNfd/XmsQMZ/78+Rg7diyeeeYZWXtqaioyMzPh7u4utanVagwbNgyxsbEAgMTERJSWlspqtFotnJ2dpZq4uDhoNBopbABg4MCB0Gg0shpnZ2fZLbQ9PDxQXFyMxMTEKvseFBQknabTaDRwcHB4gFeCiKjpavSBEx4ejh9++AFBQUF6yzIzMwEAdnZ2snY7OztpWWZmJoyNjWFlZVVtja2trd72bW1tZTX37sfKygrGxsZSTWUCAgKg0+mkR3p6+v2GTETULD3QDdgetvT0dLz++uuIioqCiYlJlXUqlUr2XAih13ave2sqq69Lzb3UajXvhEpEhEY+w0lMTERWVhZcXFxgaGgIQ0NDREdH47333oOhoaE047h3hpGVlSUts7e3R0lJCXJzc6ut+fPPP/X2n52dLau5dz+5ubkoLS3Vm/kQEZG+Rh04I0eOxE8//YSkpCTp0bdvX7z88stISkpC586dYW9vj2PHjknrlJSUIDo6GoMGDQIAuLi4wMjISFaTkZGB5ORkqcbV1RU6nQ5nzpyRak6fPg2dTierSU5ORkZGhlQTFRUFtVoNFxeXh/o6EBE1B436lJqFhQWcnZ1lbebm5rC2tpba/fz8EBgYiK5du6Jr164IDAyEmZkZvLy8AAAajQazZs2Cv78/rK2t0bp1ayxevBg9e/aULkLo0aMHRo8ejTlz5uCDDz4AALzyyivw9PSEo6MjAMDd3R1OTk7w9vbGxo0bkZOTg8WLF2POnDl1utqMiOhR06gDpyaWLl2KoqIi+Pj4IDc3FwMGDEBUVBQsLCykmi1btsDQ0BCTJ09GUVERRo4cibCwMBgYGEg1e/bsga+vr3Q12/jx47Ft2zZpuYGBAQ4fPgwfHx8MHjwYpqam8PLywqZNm5QbLBFRE9YkvofTnNT0evWq8Hs4jxZ+D4eagmb1PRwiImr6GDhERKQIBg4RESmCgUNERIpg4BARkSIYOEREpAgGDhERKYKBQ0REimDgEBGRIhg4RESkCAYOEREpgoFDRESKYOAQEZEiGDhERKQIBg4RESmCgUNERIpg4BARkSIYOEREpAgGDhERKYKBQ0REimDgEBGRIhg4RESkCAYOEREpgoFDRESKYOAQEZEiGDhERKQIBg4RESmCgUNERIpg4BARkSIYOEREpAgGDhERKYKBQ0REimDgEBGRIhg4RESkCAYOEREpgoFDRESKYOAQEZEiGDhERKQIBg4RESmCgUNERIpg4BARkSIYOEREpAgGDhERKYKBQ0REimDgEFGTcerUKYwbNw5arRYqlQpfffWVXs3Fixcxfvx4aDQaWFhYYODAgUhLS6t2uwcOHICTkxPUajWcnJwQEREhW96xY0eoVCq9x/z586WaTZs2wc7ODnZ2dtiyZYts/dOnT8PFxQVlZWV1H3wzwMAhoiajsLAQvXv3xrZt2ypd/ttvv2HIkCHo3r07Tp48iXPnzmHlypUwMTGpcptxcXGYMmUKvL29ce7cOXh7e2Py5Mk4ffq0VJOQkICMjAzpcezYMQDApEmTAAA//fQT3nrrLezbtw979+7FG2+8geTkZABAaWkp5s2bhx07dsDAwKC+XoomybChO0BEVFPPPvssnn322SqXr1ixAmPGjEFwcLDU1rlz52q3GRISglGjRiEgIAAAEBAQgOjoaISEhGDfvn0AgDZt2sjWWb9+PR5//HEMGzYMwJ1ZVa9evTBixAgAQK9evXDx4kU4Oztj48aNGDp0KPr161f7ATczjXqGExQUhH79+sHCwgK2trZ47rnncPnyZVmNEAKrV6+GVquFqakp3NzccOHCBVlNcXExFixYABsbG5ibm2P8+PG4du2arCY3Nxfe3t7QaDTQaDTw9vZGXl6erCYtLQ3jxo2Dubk5bGxs4Ovri5KSkocydiKqnfLychw+fBjdunWDh4cHbG1tMWDAgEpPu90tLi4O7u7usjYPDw/ExsZWWl9SUoLdu3dj5syZUKlUAICePXsiJSUFaWlpuHr1KlJSUuDs7Ixff/0VYWFhWLduXb2Msalr1IETHR2N+fPnIz4+HseOHcPt27fh7u6OwsJCqSY4OBibN2/Gtm3bkJCQAHt7e4waNQo3btyQavz8/BAREYHw8HDExMSgoKAAnp6esvOpXl5eSEpKQmRkJCIjI5GUlARvb29peVlZGcaOHYvCwkLExMQgPDwcBw4cgL+/vzIvBhFVKysrCwUFBVi/fj1Gjx6NqKgoPP/885g4cSKio6OrXC8zMxN2dnayNjs7O2RmZlZa/9VXXyEvLw8zZsyQ2nr06IHAwECMGjUK7u7uCAoKQo8ePTBv3jwEBwfjm2++gbOzM5588kmcOnWqXsbbFDXqU2qRkZGy57t27YKtrS0SExMxdOhQCCEQEhKCFStWYOLEiQCATz75BHZ2dti7dy/mzp0LnU6H0NBQfPbZZ3jmmWcAALt374aDgwOOHz8ODw8PXLx4EZGRkYiPj8eAAQMAADt37oSrqysuX74MR0dHREVF4eeff0Z6ejq0Wi0A4F//+hdmzJiBd955B5aWlgq+MkR0r/LycgDAhAkTsHDhQgBAnz59EBsbix07dkinvypTMVOpIITQa6sQGhqKZ599VnofqDBv3jzMmzdPeh4WFgYLCwu4urrC0dERCQkJuHbtGl566SWkpqZCrVbXaZxNWaOe4dxLp9MBAFq3bg0ASE1NRWZmpmw6rFarMWzYMGk6nJiYiNLSUlmNVquFs7OzVBMXFweNRiOFDQAMHDgQGo1GVuPs7Cw7yDw8PFBcXIzExMQq+1xcXIz8/HzZg4jqn42NDQwNDeHk5CRr79GjR7VXqdnb2+vNZrKysvRmPQBw9epVHD9+HLNnz662L3/99RfWrl2LrVu34vTp0+jWrRu6du2K4cOHo7S0FCkpKbUYWfPRZAJHCIFFixZhyJAhcHZ2BgDpIKluOpyZmQljY2NYWVlVW2Nra6u3T1tbW1nNvfuxsrKCsbFxlVNv4M7nUBWfC2k0Gjg4ONRm2ERUQ8bGxujXr5/e57wpKSno0KFDleu5urpKV51ViIqKwqBBg/RqK86yjB07ttq++Pn5YeHChWjfvj3KyspQWloqLbt9+/Yje3l0oz6ldrfXXnsN58+fR0xMjN6y2kyHq6qprL4uNfcKCAjAokWLpOf5+fkMHaI6KigowK+//io9T01NRVJSElq3bo3HHnsMS5YswZQpUzB06FAMHz4ckZGR+Prrr3Hy5ElpnX/84x9o164dgoKCAACvv/46hg4dig0bNmDChAk4ePAgjh8/rvdeU15ejl27dmH69OkwNKz6rfPYsWP45Zdf8OmnnwIA+vfvj0uXLuHo0aNIT0+HgYEBHB0d6/FVaTqaROAsWLAAhw4dwqlTp9C+fXup3d7eHsCd2Ufbtm2l9runw/b29igpKUFubq5slpOVlSX9BWNvb48///xTb7/Z2dmy7dx9XT5w58q20tLSSqfeFdRq9SN5rpboYTh79iyGDx8uPa/4Y2769OkICwvD888/jx07diAoKAi+vr5wdHTEgQMHMGTIEGmdtLQ0tGjxfyd3Bg0ahPDwcLz55ptYuXIlHn/8cezfv192ih0Ajh8/jrS0NMycObPK/hUVFeG1117D/v37pX20a9cOW7duxT//+U+o1Wp88sknMDU1rZfXo6lRCSFEQ3eiKkIILFiwABERETh58iS6du2qt1yr1WLhwoVYunQpgDuXLNra2mLDhg3SRQNt2rTB7t27MXnyZABARkYG2rdvjyNHjkgXDTg5OeH06dPo378/gDvfDB44cCAuXboER0dHHD16FJ6enrh27ZoUbvv378f06dORlZVV44sG8vPzodFooNPp6nShwfaER/cKl0fRq/2GNti+i4pONNi+SXmmpiPrvG5N39ca9Qxn/vz52Lt3Lw4ePAgLCwvpsxKNRgNTU1OoVCr4+fkhMDAQXbt2RdeuXREYGAgzMzN4eXlJtbNmzYK/vz+sra3RunVrLF68GD179pSuWuvRowdGjx6NOXPm4IMPPgAAvPLKK/D09JSmvu7u7nBycoK3tzc2btyInJwcLF68GHPmzOEVakRENdCoA2f79u0AADc3N1n7rl27pGvgly5diqKiIvj4+CA3NxcDBgxAVFQULCwspPotW7bA0NAQkydPRlFREUaOHImwsDDZz0zs2bMHvr6+0tVs48ePl/18hoGBAQ4fPgwfHx8MHjwYpqam8PLywqZNmx7S6ImImpdGfUqtOeIpNaoNnlIjpShxSq3JXBZNRERNGwOHiIgUwcAhIiJFMHCIiEgRDBwiIlIEA4eIiBTBwCEiIkUwcIiISBEMHCIiUgQDh4iIFMHAISIiRTBwiIhIEQwcIiJSBAOHiIgUwcAhIiJFMHCIiEgRDBwiIlIEA4eIiBTBwCEiIkUwcIiISBEMHCIiUgQDh4iIFMHAISIiRTBwiIhIEQwcIiJSBAOHiIgUwcAhIiJFMHCIiEgRDBwiIlIEA4eIiBTBwCEiIkUwcIiISBEMHCIiUgQDh4iIFMHAISIiRTBwiIhIEQwcIiJSBAOHiIgUwcAhIiJFMHCIiEgRDBwiIlIEA4eIiBTBwCEiIkUwcIiISBEMHCIiUgQDh4iIFMHAISIiRTBwiIhIEQycOnj//ffRqVMnmJiYwMXFBd99911Dd4mIqNFj4NTS/v374efnhxUrVuDHH3/E008/jWeffRZpaWkN3TUiokaNgVNLmzdvxqxZszB79mz06NEDISEhcHBwwPbt2xu6a0REjZphQ3egKSkpKUFiYiKWL18ua3d3d0dsbGyl6xQXF6O4uFh6rtPpAAD5+fl16kNRQWGd1qOmqa7HSX0oKuKx9igpLa37sVZxnAohqq1j4NTCX3/9hbKyMtjZ2cna7ezskJmZWek6QUFBWLNmjV67g4PDQ+kjNS/+Dd0Bolq4ceMGNBpNlcsZOHWgUqlkz4UQem0VAgICsGjRIul5eXk5cnJyYG1tXeU6JJefnw8HBwekp6fD0tKyobtDzRiPtboRQuDGjRvQarXV1jFwasHGxgYGBgZ6s5msrCy9WU8FtVoNtVota2vVqtXD6mKzZmlpyTcBUgSPtdqrbmZTgRcN1IKxsTFcXFxw7NgxWfuxY8cwaNCgBuoVEVHTwBlOLS1atAje3t7o27cvXF1d8eGHHyItLQ3z5s1r6K4RETVqDJxamjJlCv7++2+sXbsWGRkZcHZ2xpEjR9ChQ4eG7lqzpVarsWrVKr1Tk0T1jcfaw6US97uOjYiIqB7wMxwiIlIEA4eIiBTBwCEiIkUwcIiISBEMHFLEjBkzoFKp9B6//vorACAwMBAGBgZYv3693rphYWF6X5a9ePEi2rdvj4kTJ6K4uBgnT56sdPsqlarKnx2i5unuY83Q0BCPPfYYXn31VeTm5ko1HTt2rPRYqez4c3d3h4GBAeLj4yvd13PPPfcwh9OsMHBIMaNHj0ZGRobs0alTJwDArl27sHTpUnz88cf33U5CQgKefvppeHh44IsvvpBdwnr58mW9fdja2j60MVHjVHGsXblyBR999BG+/vpr+Pj4yGoqvtpw92PBggWymrS0NMTFxeG1115DaGiokkNolvg9HFKMWq2Gvb29Xnt0dDSKioqwdu1afPrppzh16hSGDh1a6Tb+97//YcKECZg3bx42btyot9zW1pY/HUSyY619+/aYMmUKwsLCZDUWFhaVHo9327VrFzw9PfHqq6+if//+CAkJgbm5+cPqdrPHGQ41uNDQUEydOhVGRkaYOnVqlX9JRkREYOzYsVixYkWlYUNUmd9//x2RkZEwMjKq1XpCCOzatQvTpk1D9+7d0a1bN3z++ecPqZePBgYOKea///0vWrZsKT0mTZqE/Px8HDhwANOmTQMATJs2DV9++aXefWAKCgowadIkLFmyRO9+RHdr3769bB+Ojo4PdUzUOFUca6ampnj88cfx888/Y9myZbKaZcuWyY6Vli1b4uTJk9Ly48eP4+bNm/Dw8ABw59jkabUHw1NqpJjhw4fL7oxqbm6OvXv3onPnzujduzcAoE+fPujcuTPCw8PxyiuvSLWmpqYYMmQIdu7cialTp6JHjx6V7uO7776DhYWF9NzQkIf4o6jiWLt58yY++ugjpKSk6H0+s2TJEsyYMUPW1q5dO+m/Q0NDMWXKFOkYmjp1KpYsWYLLly/zD5k64gyHFGNubo4uXbpIj7Zt2+Ljjz/GhQsXYGhoKD0uXLig95ekgYEBvvrqK7i4uGD48OH4+eefK91Hp06dZPvo2LGjAiOjxqbiWOvVqxfee+89FBcX690I0cbGRnasdOnSBaampgCAnJwcfPXVV3j//fel47Jdu3a4fft2jS5socoxcKjB/PTTTzh79ixOnjyJpKQk6XHq1CkkJCQgOTlZVq9Wq/Gf//wH/fv3x/Dhw/WWE1Vl1apV2LRpE65fv16j+j179qB9+/Y4d+6c7NgMCQnBJ598gtu3bz/kHjdPPN9ADSY0NBT9+/ev9Io0V1dXhIaGYsuWLbJ2Y2NjHDhwAJMnT8aIESNw4sQJ9OzZU1qelZWFW7duydaxtrau9QfG1Ly4ubnhiSeeQGBgILZt2wbgzu2Q7/2OlpmZGSwtLREaGooXX3wRzs7OsuUdOnTAsmXLcPjwYUyYMAEAoNPpkJSUJKtr3bo1HnvssYc3oCaKMxxqECUlJdi9ezdeeOGFSpe/8MIL2L17N0pKSvSWGRkZ4fPPP8fQoUMxYsQInD9/Xlrm6OiItm3byh6JiYkPbRzUdCxatAg7d+5Eeno6AOCtt97SO1aWLl2KxMREnDt3rtJj08LCAu7u7rJTvidPnsSTTz4pe7z11luKjasp4e0JiIhIEZzhEBGRIhg4RESkCAYOEREpgoFDRESKYOAQEZEiGDhERKQIBg4RESmCgUNERIpg4BA1Ym5ubvDz86tRbcVttvPy8h5onx07dkRISMgDbYOoMgwcIiJSBAOHiIgUwcAhaiJ2796Nvn37wsLCAvb29vDy8kJWVpZe3ffff4/evXvDxMQEAwYMwE8//SRbHhsbi6FDh8LU1BQODg7w9fVFYWGhUsOgRxgDh6iJKCkpwdtvv41z587hq6++Qmpqqt4dK4E7d7LctGkTEhISYGtri/Hjx6O0tBTAnXsQeXh4YOLEiTh//jz279+PmJgYvPbaawqPhh5FvB8OURMxc+ZM6b87d+6M9957D/3790dBQQFatmwpLVu1ahVGjRoFAPjkk0/Qvn17REREYPLkydi4cSO8vLykCxG6du2K9957D8OGDcP27dthYmKi6Jjo0cIZDlET8eOPP2LChAno0KEDLCws4ObmBgBIS0uT1bm6ukr/3bp1azg6OuLixYsAgMTERISFhaFly5bSw8PDA+Xl5UhNTVVsLPRo4gyHqAkoLCyEu7s73N3dsXv3brRp0wZpaWnw8PCo9CZ191KpVACA8vJyzJ07F76+vno1vEMlPWwMHKIm4NKlS/jrr7+wfv16ODg4AADOnj1baW18fLwUHrm5uUhJSUH37t0BAE899RQuXLiALl26KNNxorvwlBpRE/DYY4/B2NgYW7duxe+//45Dhw7h7bffrrR27dq1OHHiBJKTkzFjxgzY2NjgueeeAwAsW7YMcXFxmD9/PpKSkvDLL7/g0KFDWLBggYKjoUcVA4eoCWjTpg3CwsLwxRdfwMnJCevXr8emTZsqrV2/fj1ef/11uLi4ICMjA4cOHYKxsTEAoFevXoiOjsYvv/yCp59+Gk8++SRWrlyJtm3bKjkcekSphBCioTtBRETNH2c4RESkCAYOEREpgoFDRESKYOAQEZEiGDhERKQIBg4RESmCgUNERIpg4BARkSIYOEREpAgGDhERKYKBQ0REivh/TLmxSIkdizMAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 400x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_count('label', 'label (train)', meta_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use DataLoader to load the videos \n",
    "\n",
    "1. **shuffle:** ON\n",
    "2. **batch size:** 3\n",
    "3. **source:** DATA_FOLDER\n",
    "4. **compressed data:** COMPRESSED_DATA_FOLDER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = DataLoader(VideoDataset(DATA_FOLDER, 'train'), batch_size=3, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data, label = next(iter(loader))\n",
    "# fig = plt.figure(figsize=(12, 12))\n",
    "\n",
    "# for i in range(BATCH_SIZE):\n",
    "#   video = data[i]\n",
    "#   fig.add_subplot(BATCH_SIZE, 3, BATCH_SIZE*i + 1)\n",
    "#   plt.imshow(video[0])\n",
    "#   fig.add_subplot(BATCH_SIZE, 3, BATCH_SIZE*i + 2)\n",
    "#   plt.imshow(video[100])\n",
    "#   fig.add_subplot(BATCH_SIZE, 3, BATCH_SIZE*i + 3)\n",
    "#   plt.imshow(video[-1])\n",
    "\n",
    "# print(label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import glob\n",
    "\n",
    "class TensorDataset(Dataset):\n",
    "    def __init__(self, tensor_files):\n",
    "        self.tensor_files = tensor_files\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.tensor_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        tensor_data = torch.load(self.tensor_files[idx])\n",
    "        inputs = tensor_data['inputs']  # Assuming the file contains a dictionary with 'inputs'\n",
    "        labels = tensor_data['labels']  # Assuming the file contains a dictionary with 'labels'\n",
    "        return inputs, labels\n",
    "\n",
    "# List all tensor files in a directory\n",
    "tensor_files = glob.glob('path_to_tensor_files/*.pt')\n",
    "\n",
    "# Create the dataset\n",
    "dataset = TensorDataset(tensor_files)\n",
    "\n",
    "# Create the DataLoader\n",
    "dataloader = DataLoader(dataset, batch_size=4, shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "         ZeroPad2d-1     [-1, 1, 201, 201, 201]               0\n",
      "Conv3dStaticSamePadding-2    [-1, 32, 100, 100, 100]             864\n",
      "       BatchNorm3d-3    [-1, 32, 100, 100, 100]              64\n",
      "MemoryEfficientSwish-4    [-1, 32, 100, 100, 100]               0\n",
      "         ZeroPad2d-5    [-1, 32, 101, 101, 101]               0\n",
      "Conv3dStaticSamePadding-6       [-1, 32, 50, 50, 50]             864\n",
      "       BatchNorm3d-7       [-1, 32, 50, 50, 50]              64\n",
      "MemoryEfficientSwish-8       [-1, 32, 50, 50, 50]               0\n",
      "          Identity-9          [-1, 32, 1, 1, 1]               0\n",
      "Conv3dStaticSamePadding-10           [-1, 8, 1, 1, 1]             264\n",
      "MemoryEfficientSwish-11           [-1, 8, 1, 1, 1]               0\n",
      "         Identity-12           [-1, 8, 1, 1, 1]               0\n",
      "Conv3dStaticSamePadding-13          [-1, 32, 1, 1, 1]             288\n",
      "         Identity-14       [-1, 32, 50, 50, 50]               0\n",
      "Conv3dStaticSamePadding-15       [-1, 16, 50, 50, 50]             512\n",
      "      BatchNorm3d-16       [-1, 16, 50, 50, 50]              32\n",
      "    MBConvBlock3D-17       [-1, 16, 50, 50, 50]               0\n",
      "         Identity-18       [-1, 16, 50, 50, 50]               0\n",
      "Conv3dStaticSamePadding-19       [-1, 96, 50, 50, 50]           1,536\n",
      "      BatchNorm3d-20       [-1, 96, 50, 50, 50]             192\n",
      "MemoryEfficientSwish-21       [-1, 96, 50, 50, 50]               0\n",
      "        ZeroPad2d-22       [-1, 96, 51, 51, 51]               0\n",
      "Conv3dStaticSamePadding-23       [-1, 96, 25, 25, 25]           2,592\n",
      "      BatchNorm3d-24       [-1, 96, 25, 25, 25]             192\n",
      "MemoryEfficientSwish-25       [-1, 96, 25, 25, 25]               0\n",
      "         Identity-26          [-1, 96, 1, 1, 1]               0\n",
      "Conv3dStaticSamePadding-27           [-1, 4, 1, 1, 1]             388\n",
      "MemoryEfficientSwish-28           [-1, 4, 1, 1, 1]               0\n",
      "         Identity-29           [-1, 4, 1, 1, 1]               0\n",
      "Conv3dStaticSamePadding-30          [-1, 96, 1, 1, 1]             480\n",
      "         Identity-31       [-1, 96, 25, 25, 25]               0\n",
      "Conv3dStaticSamePadding-32       [-1, 24, 25, 25, 25]           2,304\n",
      "      BatchNorm3d-33       [-1, 24, 25, 25, 25]              48\n",
      "    MBConvBlock3D-34       [-1, 24, 25, 25, 25]               0\n",
      "         Identity-35       [-1, 24, 25, 25, 25]               0\n",
      "Conv3dStaticSamePadding-36      [-1, 144, 25, 25, 25]           3,456\n",
      "      BatchNorm3d-37      [-1, 144, 25, 25, 25]             288\n",
      "MemoryEfficientSwish-38      [-1, 144, 25, 25, 25]               0\n",
      "        ZeroPad2d-39      [-1, 144, 27, 27, 27]               0\n",
      "Conv3dStaticSamePadding-40      [-1, 144, 25, 25, 25]           3,888\n",
      "      BatchNorm3d-41      [-1, 144, 25, 25, 25]             288\n",
      "MemoryEfficientSwish-42      [-1, 144, 25, 25, 25]               0\n",
      "         Identity-43         [-1, 144, 1, 1, 1]               0\n",
      "Conv3dStaticSamePadding-44           [-1, 6, 1, 1, 1]             870\n",
      "MemoryEfficientSwish-45           [-1, 6, 1, 1, 1]               0\n",
      "         Identity-46           [-1, 6, 1, 1, 1]               0\n",
      "Conv3dStaticSamePadding-47         [-1, 144, 1, 1, 1]           1,008\n",
      "         Identity-48      [-1, 144, 25, 25, 25]               0\n",
      "Conv3dStaticSamePadding-49       [-1, 24, 25, 25, 25]           3,456\n",
      "      BatchNorm3d-50       [-1, 24, 25, 25, 25]              48\n",
      "    MBConvBlock3D-51       [-1, 24, 25, 25, 25]               0\n",
      "         Identity-52       [-1, 24, 25, 25, 25]               0\n",
      "Conv3dStaticSamePadding-53      [-1, 144, 25, 25, 25]           3,456\n",
      "      BatchNorm3d-54      [-1, 144, 25, 25, 25]             288\n",
      "MemoryEfficientSwish-55      [-1, 144, 25, 25, 25]               0\n",
      "        ZeroPad2d-56      [-1, 144, 28, 28, 28]               0\n",
      "Conv3dStaticSamePadding-57      [-1, 144, 12, 12, 12]          18,000\n",
      "      BatchNorm3d-58      [-1, 144, 12, 12, 12]             288\n",
      "MemoryEfficientSwish-59      [-1, 144, 12, 12, 12]               0\n",
      "         Identity-60         [-1, 144, 1, 1, 1]               0\n",
      "Conv3dStaticSamePadding-61           [-1, 6, 1, 1, 1]             870\n",
      "MemoryEfficientSwish-62           [-1, 6, 1, 1, 1]               0\n",
      "         Identity-63           [-1, 6, 1, 1, 1]               0\n",
      "Conv3dStaticSamePadding-64         [-1, 144, 1, 1, 1]           1,008\n",
      "         Identity-65      [-1, 144, 12, 12, 12]               0\n",
      "Conv3dStaticSamePadding-66       [-1, 40, 12, 12, 12]           5,760\n",
      "      BatchNorm3d-67       [-1, 40, 12, 12, 12]              80\n",
      "    MBConvBlock3D-68       [-1, 40, 12, 12, 12]               0\n",
      "         Identity-69       [-1, 40, 12, 12, 12]               0\n",
      "Conv3dStaticSamePadding-70      [-1, 240, 12, 12, 12]           9,600\n",
      "      BatchNorm3d-71      [-1, 240, 12, 12, 12]             480\n",
      "MemoryEfficientSwish-72      [-1, 240, 12, 12, 12]               0\n",
      "        ZeroPad2d-73      [-1, 240, 16, 16, 16]               0\n",
      "Conv3dStaticSamePadding-74      [-1, 240, 12, 12, 12]          30,000\n",
      "      BatchNorm3d-75      [-1, 240, 12, 12, 12]             480\n",
      "MemoryEfficientSwish-76      [-1, 240, 12, 12, 12]               0\n",
      "         Identity-77         [-1, 240, 1, 1, 1]               0\n",
      "Conv3dStaticSamePadding-78          [-1, 10, 1, 1, 1]           2,410\n",
      "MemoryEfficientSwish-79          [-1, 10, 1, 1, 1]               0\n",
      "         Identity-80          [-1, 10, 1, 1, 1]               0\n",
      "Conv3dStaticSamePadding-81         [-1, 240, 1, 1, 1]           2,640\n",
      "         Identity-82      [-1, 240, 12, 12, 12]               0\n",
      "Conv3dStaticSamePadding-83       [-1, 40, 12, 12, 12]           9,600\n",
      "      BatchNorm3d-84       [-1, 40, 12, 12, 12]              80\n",
      "    MBConvBlock3D-85       [-1, 40, 12, 12, 12]               0\n",
      "         Identity-86       [-1, 40, 12, 12, 12]               0\n",
      "Conv3dStaticSamePadding-87      [-1, 240, 12, 12, 12]           9,600\n",
      "      BatchNorm3d-88      [-1, 240, 12, 12, 12]             480\n",
      "MemoryEfficientSwish-89      [-1, 240, 12, 12, 12]               0\n",
      "        ZeroPad2d-90      [-1, 240, 13, 13, 13]               0\n",
      "Conv3dStaticSamePadding-91         [-1, 240, 6, 6, 6]           6,480\n",
      "      BatchNorm3d-92         [-1, 240, 6, 6, 6]             480\n",
      "MemoryEfficientSwish-93         [-1, 240, 6, 6, 6]               0\n",
      "         Identity-94         [-1, 240, 1, 1, 1]               0\n",
      "Conv3dStaticSamePadding-95          [-1, 10, 1, 1, 1]           2,410\n",
      "MemoryEfficientSwish-96          [-1, 10, 1, 1, 1]               0\n",
      "         Identity-97          [-1, 10, 1, 1, 1]               0\n",
      "Conv3dStaticSamePadding-98         [-1, 240, 1, 1, 1]           2,640\n",
      "         Identity-99         [-1, 240, 6, 6, 6]               0\n",
      "Conv3dStaticSamePadding-100          [-1, 80, 6, 6, 6]          19,200\n",
      "     BatchNorm3d-101          [-1, 80, 6, 6, 6]             160\n",
      "   MBConvBlock3D-102          [-1, 80, 6, 6, 6]               0\n",
      "        Identity-103          [-1, 80, 6, 6, 6]               0\n",
      "Conv3dStaticSamePadding-104         [-1, 480, 6, 6, 6]          38,400\n",
      "     BatchNorm3d-105         [-1, 480, 6, 6, 6]             960\n",
      "MemoryEfficientSwish-106         [-1, 480, 6, 6, 6]               0\n",
      "       ZeroPad2d-107         [-1, 480, 8, 8, 8]               0\n",
      "Conv3dStaticSamePadding-108         [-1, 480, 6, 6, 6]          12,960\n",
      "     BatchNorm3d-109         [-1, 480, 6, 6, 6]             960\n",
      "MemoryEfficientSwish-110         [-1, 480, 6, 6, 6]               0\n",
      "        Identity-111         [-1, 480, 1, 1, 1]               0\n",
      "Conv3dStaticSamePadding-112          [-1, 20, 1, 1, 1]           9,620\n",
      "MemoryEfficientSwish-113          [-1, 20, 1, 1, 1]               0\n",
      "        Identity-114          [-1, 20, 1, 1, 1]               0\n",
      "Conv3dStaticSamePadding-115         [-1, 480, 1, 1, 1]          10,080\n",
      "        Identity-116         [-1, 480, 6, 6, 6]               0\n",
      "Conv3dStaticSamePadding-117          [-1, 80, 6, 6, 6]          38,400\n",
      "     BatchNorm3d-118          [-1, 80, 6, 6, 6]             160\n",
      "   MBConvBlock3D-119          [-1, 80, 6, 6, 6]               0\n",
      "        Identity-120          [-1, 80, 6, 6, 6]               0\n",
      "Conv3dStaticSamePadding-121         [-1, 480, 6, 6, 6]          38,400\n",
      "     BatchNorm3d-122         [-1, 480, 6, 6, 6]             960\n",
      "MemoryEfficientSwish-123         [-1, 480, 6, 6, 6]               0\n",
      "       ZeroPad2d-124         [-1, 480, 8, 8, 8]               0\n",
      "Conv3dStaticSamePadding-125         [-1, 480, 6, 6, 6]          12,960\n",
      "     BatchNorm3d-126         [-1, 480, 6, 6, 6]             960\n",
      "MemoryEfficientSwish-127         [-1, 480, 6, 6, 6]               0\n",
      "        Identity-128         [-1, 480, 1, 1, 1]               0\n",
      "Conv3dStaticSamePadding-129          [-1, 20, 1, 1, 1]           9,620\n",
      "MemoryEfficientSwish-130          [-1, 20, 1, 1, 1]               0\n",
      "        Identity-131          [-1, 20, 1, 1, 1]               0\n",
      "Conv3dStaticSamePadding-132         [-1, 480, 1, 1, 1]          10,080\n",
      "        Identity-133         [-1, 480, 6, 6, 6]               0\n",
      "Conv3dStaticSamePadding-134          [-1, 80, 6, 6, 6]          38,400\n",
      "     BatchNorm3d-135          [-1, 80, 6, 6, 6]             160\n",
      "   MBConvBlock3D-136          [-1, 80, 6, 6, 6]               0\n",
      "        Identity-137          [-1, 80, 6, 6, 6]               0\n",
      "Conv3dStaticSamePadding-138         [-1, 480, 6, 6, 6]          38,400\n",
      "     BatchNorm3d-139         [-1, 480, 6, 6, 6]             960\n",
      "MemoryEfficientSwish-140         [-1, 480, 6, 6, 6]               0\n",
      "       ZeroPad2d-141      [-1, 480, 10, 10, 10]               0\n",
      "Conv3dStaticSamePadding-142         [-1, 480, 6, 6, 6]          60,000\n",
      "     BatchNorm3d-143         [-1, 480, 6, 6, 6]             960\n",
      "MemoryEfficientSwish-144         [-1, 480, 6, 6, 6]               0\n",
      "        Identity-145         [-1, 480, 1, 1, 1]               0\n",
      "Conv3dStaticSamePadding-146          [-1, 20, 1, 1, 1]           9,620\n",
      "MemoryEfficientSwish-147          [-1, 20, 1, 1, 1]               0\n",
      "        Identity-148          [-1, 20, 1, 1, 1]               0\n",
      "Conv3dStaticSamePadding-149         [-1, 480, 1, 1, 1]          10,080\n",
      "        Identity-150         [-1, 480, 6, 6, 6]               0\n",
      "Conv3dStaticSamePadding-151         [-1, 112, 6, 6, 6]          53,760\n",
      "     BatchNorm3d-152         [-1, 112, 6, 6, 6]             224\n",
      "   MBConvBlock3D-153         [-1, 112, 6, 6, 6]               0\n",
      "        Identity-154         [-1, 112, 6, 6, 6]               0\n",
      "Conv3dStaticSamePadding-155         [-1, 672, 6, 6, 6]          75,264\n",
      "     BatchNorm3d-156         [-1, 672, 6, 6, 6]           1,344\n",
      "MemoryEfficientSwish-157         [-1, 672, 6, 6, 6]               0\n",
      "       ZeroPad2d-158      [-1, 672, 10, 10, 10]               0\n",
      "Conv3dStaticSamePadding-159         [-1, 672, 6, 6, 6]          84,000\n",
      "     BatchNorm3d-160         [-1, 672, 6, 6, 6]           1,344\n",
      "MemoryEfficientSwish-161         [-1, 672, 6, 6, 6]               0\n",
      "        Identity-162         [-1, 672, 1, 1, 1]               0\n",
      "Conv3dStaticSamePadding-163          [-1, 28, 1, 1, 1]          18,844\n",
      "MemoryEfficientSwish-164          [-1, 28, 1, 1, 1]               0\n",
      "        Identity-165          [-1, 28, 1, 1, 1]               0\n",
      "Conv3dStaticSamePadding-166         [-1, 672, 1, 1, 1]          19,488\n",
      "        Identity-167         [-1, 672, 6, 6, 6]               0\n",
      "Conv3dStaticSamePadding-168         [-1, 112, 6, 6, 6]          75,264\n",
      "     BatchNorm3d-169         [-1, 112, 6, 6, 6]             224\n",
      "   MBConvBlock3D-170         [-1, 112, 6, 6, 6]               0\n",
      "        Identity-171         [-1, 112, 6, 6, 6]               0\n",
      "Conv3dStaticSamePadding-172         [-1, 672, 6, 6, 6]          75,264\n",
      "     BatchNorm3d-173         [-1, 672, 6, 6, 6]           1,344\n",
      "MemoryEfficientSwish-174         [-1, 672, 6, 6, 6]               0\n",
      "       ZeroPad2d-175      [-1, 672, 10, 10, 10]               0\n",
      "Conv3dStaticSamePadding-176         [-1, 672, 6, 6, 6]          84,000\n",
      "     BatchNorm3d-177         [-1, 672, 6, 6, 6]           1,344\n",
      "MemoryEfficientSwish-178         [-1, 672, 6, 6, 6]               0\n",
      "        Identity-179         [-1, 672, 1, 1, 1]               0\n",
      "Conv3dStaticSamePadding-180          [-1, 28, 1, 1, 1]          18,844\n",
      "MemoryEfficientSwish-181          [-1, 28, 1, 1, 1]               0\n",
      "        Identity-182          [-1, 28, 1, 1, 1]               0\n",
      "Conv3dStaticSamePadding-183         [-1, 672, 1, 1, 1]          19,488\n",
      "        Identity-184         [-1, 672, 6, 6, 6]               0\n",
      "Conv3dStaticSamePadding-185         [-1, 112, 6, 6, 6]          75,264\n",
      "     BatchNorm3d-186         [-1, 112, 6, 6, 6]             224\n",
      "   MBConvBlock3D-187         [-1, 112, 6, 6, 6]               0\n",
      "        Identity-188         [-1, 112, 6, 6, 6]               0\n",
      "Conv3dStaticSamePadding-189         [-1, 672, 6, 6, 6]          75,264\n",
      "     BatchNorm3d-190         [-1, 672, 6, 6, 6]           1,344\n",
      "MemoryEfficientSwish-191         [-1, 672, 6, 6, 6]               0\n",
      "       ZeroPad2d-192         [-1, 672, 9, 9, 9]               0\n",
      "Conv3dStaticSamePadding-193         [-1, 672, 3, 3, 3]          84,000\n",
      "     BatchNorm3d-194         [-1, 672, 3, 3, 3]           1,344\n",
      "MemoryEfficientSwish-195         [-1, 672, 3, 3, 3]               0\n",
      "        Identity-196         [-1, 672, 1, 1, 1]               0\n",
      "Conv3dStaticSamePadding-197          [-1, 28, 1, 1, 1]          18,844\n",
      "MemoryEfficientSwish-198          [-1, 28, 1, 1, 1]               0\n",
      "        Identity-199          [-1, 28, 1, 1, 1]               0\n",
      "Conv3dStaticSamePadding-200         [-1, 672, 1, 1, 1]          19,488\n",
      "        Identity-201         [-1, 672, 3, 3, 3]               0\n",
      "Conv3dStaticSamePadding-202         [-1, 192, 3, 3, 3]         129,024\n",
      "     BatchNorm3d-203         [-1, 192, 3, 3, 3]             384\n",
      "   MBConvBlock3D-204         [-1, 192, 3, 3, 3]               0\n",
      "        Identity-205         [-1, 192, 3, 3, 3]               0\n",
      "Conv3dStaticSamePadding-206        [-1, 1152, 3, 3, 3]         221,184\n",
      "     BatchNorm3d-207        [-1, 1152, 3, 3, 3]           2,304\n",
      "MemoryEfficientSwish-208        [-1, 1152, 3, 3, 3]               0\n",
      "       ZeroPad2d-209        [-1, 1152, 7, 7, 7]               0\n",
      "Conv3dStaticSamePadding-210        [-1, 1152, 3, 3, 3]         144,000\n",
      "     BatchNorm3d-211        [-1, 1152, 3, 3, 3]           2,304\n",
      "MemoryEfficientSwish-212        [-1, 1152, 3, 3, 3]               0\n",
      "        Identity-213        [-1, 1152, 1, 1, 1]               0\n",
      "Conv3dStaticSamePadding-214          [-1, 48, 1, 1, 1]          55,344\n",
      "MemoryEfficientSwish-215          [-1, 48, 1, 1, 1]               0\n",
      "        Identity-216          [-1, 48, 1, 1, 1]               0\n",
      "Conv3dStaticSamePadding-217        [-1, 1152, 1, 1, 1]          56,448\n",
      "        Identity-218        [-1, 1152, 3, 3, 3]               0\n",
      "Conv3dStaticSamePadding-219         [-1, 192, 3, 3, 3]         221,184\n",
      "     BatchNorm3d-220         [-1, 192, 3, 3, 3]             384\n",
      "   MBConvBlock3D-221         [-1, 192, 3, 3, 3]               0\n",
      "        Identity-222         [-1, 192, 3, 3, 3]               0\n",
      "Conv3dStaticSamePadding-223        [-1, 1152, 3, 3, 3]         221,184\n",
      "     BatchNorm3d-224        [-1, 1152, 3, 3, 3]           2,304\n",
      "MemoryEfficientSwish-225        [-1, 1152, 3, 3, 3]               0\n",
      "       ZeroPad2d-226        [-1, 1152, 7, 7, 7]               0\n",
      "Conv3dStaticSamePadding-227        [-1, 1152, 3, 3, 3]         144,000\n",
      "     BatchNorm3d-228        [-1, 1152, 3, 3, 3]           2,304\n",
      "MemoryEfficientSwish-229        [-1, 1152, 3, 3, 3]               0\n",
      "        Identity-230        [-1, 1152, 1, 1, 1]               0\n",
      "Conv3dStaticSamePadding-231          [-1, 48, 1, 1, 1]          55,344\n",
      "MemoryEfficientSwish-232          [-1, 48, 1, 1, 1]               0\n",
      "        Identity-233          [-1, 48, 1, 1, 1]               0\n",
      "Conv3dStaticSamePadding-234        [-1, 1152, 1, 1, 1]          56,448\n",
      "        Identity-235        [-1, 1152, 3, 3, 3]               0\n",
      "Conv3dStaticSamePadding-236         [-1, 192, 3, 3, 3]         221,184\n",
      "     BatchNorm3d-237         [-1, 192, 3, 3, 3]             384\n",
      "   MBConvBlock3D-238         [-1, 192, 3, 3, 3]               0\n",
      "        Identity-239         [-1, 192, 3, 3, 3]               0\n",
      "Conv3dStaticSamePadding-240        [-1, 1152, 3, 3, 3]         221,184\n",
      "     BatchNorm3d-241        [-1, 1152, 3, 3, 3]           2,304\n",
      "MemoryEfficientSwish-242        [-1, 1152, 3, 3, 3]               0\n",
      "       ZeroPad2d-243        [-1, 1152, 7, 7, 7]               0\n",
      "Conv3dStaticSamePadding-244        [-1, 1152, 3, 3, 3]         144,000\n",
      "     BatchNorm3d-245        [-1, 1152, 3, 3, 3]           2,304\n",
      "MemoryEfficientSwish-246        [-1, 1152, 3, 3, 3]               0\n",
      "        Identity-247        [-1, 1152, 1, 1, 1]               0\n",
      "Conv3dStaticSamePadding-248          [-1, 48, 1, 1, 1]          55,344\n",
      "MemoryEfficientSwish-249          [-1, 48, 1, 1, 1]               0\n",
      "        Identity-250          [-1, 48, 1, 1, 1]               0\n",
      "Conv3dStaticSamePadding-251        [-1, 1152, 1, 1, 1]          56,448\n",
      "        Identity-252        [-1, 1152, 3, 3, 3]               0\n",
      "Conv3dStaticSamePadding-253         [-1, 192, 3, 3, 3]         221,184\n",
      "     BatchNorm3d-254         [-1, 192, 3, 3, 3]             384\n",
      "   MBConvBlock3D-255         [-1, 192, 3, 3, 3]               0\n",
      "        Identity-256         [-1, 192, 3, 3, 3]               0\n",
      "Conv3dStaticSamePadding-257        [-1, 1152, 3, 3, 3]         221,184\n",
      "     BatchNorm3d-258        [-1, 1152, 3, 3, 3]           2,304\n",
      "MemoryEfficientSwish-259        [-1, 1152, 3, 3, 3]               0\n",
      "       ZeroPad2d-260        [-1, 1152, 5, 5, 5]               0\n",
      "Conv3dStaticSamePadding-261        [-1, 1152, 3, 3, 3]          31,104\n",
      "     BatchNorm3d-262        [-1, 1152, 3, 3, 3]           2,304\n",
      "MemoryEfficientSwish-263        [-1, 1152, 3, 3, 3]               0\n",
      "        Identity-264        [-1, 1152, 1, 1, 1]               0\n",
      "Conv3dStaticSamePadding-265          [-1, 48, 1, 1, 1]          55,344\n",
      "MemoryEfficientSwish-266          [-1, 48, 1, 1, 1]               0\n",
      "        Identity-267          [-1, 48, 1, 1, 1]               0\n",
      "Conv3dStaticSamePadding-268        [-1, 1152, 1, 1, 1]          56,448\n",
      "        Identity-269        [-1, 1152, 3, 3, 3]               0\n",
      "Conv3dStaticSamePadding-270         [-1, 320, 3, 3, 3]         368,640\n",
      "     BatchNorm3d-271         [-1, 320, 3, 3, 3]             640\n",
      "   MBConvBlock3D-272         [-1, 320, 3, 3, 3]               0\n",
      "        Identity-273         [-1, 320, 3, 3, 3]               0\n",
      "Conv3dStaticSamePadding-274        [-1, 1280, 3, 3, 3]         409,600\n",
      "     BatchNorm3d-275        [-1, 1280, 3, 3, 3]           2,560\n",
      "MemoryEfficientSwish-276        [-1, 1280, 3, 3, 3]               0\n",
      "AdaptiveAvgPool3d-277        [-1, 1280, 1, 1, 1]               0\n",
      "         Dropout-278                 [-1, 1280]               0\n",
      "          Linear-279                    [-1, 2]           2,562\n",
      "================================================================\n",
      "Total params: 4,690,942\n",
      "Trainable params: 4,690,942\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 30.52\n",
      "Forward/backward pass size (MB): 2023.29\n",
      "Params size (MB): 17.89\n",
      "Estimated Total Size (MB): 2071.70\n",
      "----------------------------------------------------------------\n",
      "[1] loss: 0.869\n",
      "[2] loss: 0.814\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from efficientnet_pytorch_3d import EfficientNet3D\n",
    "from torchsummary import summary\n",
    "\n",
    "# Check if GPU is available and set the device accordingly\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Create the model and move it to the appropriate device\n",
    "model = EfficientNet3D.from_name(\"efficientnet-b0\", override_params={'num_classes': 2}, in_channels=1).to(device)\n",
    "\n",
    "# Print model summary with the input size\n",
    "summary(model, input_size=(1, 200, 200, 200), device=str(device))\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# Training loop\n",
    "model.train()\n",
    "for epoch in range(2):\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(dataloader, 0):\n",
    "        # Get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass and optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 10 == 9:    # Print every 10 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' % (epoch + 1, i + 1, running_loss / 10))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries and set environment variables\n",
    "# os.environ[\"MKL_NUM_THREADS\"] = \"1\"\n",
    "# os.environ[\"NUMEXPR_NUM_THREADS\"] = \"1\"\n",
    "# os.environ[\"OMP_NUM_THREADS\"] = \"1\"\n",
    "\n",
    "# from albumentations import Compose, RandomBrightnessContrast, HorizontalFlip, FancyPCA, HueSaturationValue, OneOf, ToGray, ShiftScaleRotate, ImageCompression, PadIfNeeded, GaussNoise, GaussianBlur\n",
    "# from utils.augmentation import IsotropicResize\n",
    "# from collections import defaultdict\n",
    "# from sklearn.metrics import log_loss\n",
    "# from torch import topk\n",
    "# import argparse\n",
    "# import cv2\n",
    "# from training import losses\n",
    "# from training.losses import WeightedLosses\n",
    "# from training.tools.config import load_config\n",
    "\n",
    "# from utils import classifiers\n",
    "# from tensorboardX import SummaryWriter\n",
    "# from training.datasets.classifier_dataset import DeepFakeClassifierDataset\n",
    "# # from training.tools.utils import create_optimizer, AverageMeter\n",
    "# # from training.pipelines.train_classifier import train_epoch\n",
    "# # from apex import amp\n",
    "# # from apex.parallel import DistributedDataParallel, convert_syncbn_model\n",
    "# import torch\n",
    "# from torch.backends import cudnn\n",
    "# from torch.nn import DataParallel\n",
    "# from torch.utils.data import DataLoader\n",
    "# from tqdm import tqdm\n",
    "# import torch.distributed as dist\n",
    "\n",
    "# torch.backends.cudnn.benchmark = True\n",
    "# cv2.ocl.setUseOpenCL(False)\n",
    "# cv2.setNumThreads(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Train classifier functions\n",
    "\n",
    "# # Create training data transformations\n",
    "# def create_train_transforms(size=300):\n",
    "#     return Compose([\n",
    "#         ImageCompression(quality_lower=60, quality_upper=100, p=0.5),\n",
    "#         GaussNoise(p=0.1),\n",
    "#         GaussianBlur(blur_limit=3, p=0.05),\n",
    "#         HorizontalFlip(),\n",
    "#         OneOf([\n",
    "#             IsotropicResize(max_side=size, interpolation_down=cv2.INTER_AREA, interpolation_up=cv2.INTER_CUBIC),\n",
    "#             IsotropicResize(max_side=size, interpolation_down=cv2.INTER_AREA, interpolation_up=cv2.INTER_LINEAR),\n",
    "#             IsotropicResize(max_side=size, interpolation_down=cv2.INTER_LINEAR, interpolation_up=cv2.INTER_LINEAR),\n",
    "#         ], p=1),\n",
    "#         PadIfNeeded(min_height=size, min_width=size, border_mode=cv2.BORDER_CONSTANT),\n",
    "#         OneOf([RandomBrightnessContrast(), FancyPCA(), HueSaturationValue()], p=0.7),\n",
    "#         ToGray(p=0.2),\n",
    "#         ShiftScaleRotate(shift_limit=0.1, scale_limit=0.2, rotate_limit=10, border_mode=cv2.BORDER_CONSTANT, p=0.5),\n",
    "#     ])\n",
    "\n",
    "# # Create validation data transformations\n",
    "# def create_val_transforms(size=300):\n",
    "#     return Compose([\n",
    "#         IsotropicResize(max_side=size, interpolation_down=cv2.INTER_AREA, interpolation_up=cv2.INTER_CUBIC),\n",
    "#         PadIfNeeded(min_height=size, min_width=size, border_mode=cv2.BORDER_CONSTANT),\n",
    "# ])\n",
    "\n",
    "# def validate(net, data_loader, prefix=\"\"):\n",
    "#     probs = defaultdict(list)\n",
    "#     targets = defaultdict(list)\n",
    "\n",
    "#     with torch.no_grad():\n",
    "#         for sample in tqdm(data_loader):\n",
    "#             imgs = sample[\"image\"].cuda()\n",
    "#             img_names = sample[\"img_name\"]\n",
    "#             labels = sample[\"labels\"].cuda().float()\n",
    "#             out = net(imgs)\n",
    "#             labels = labels.cpu().numpy()\n",
    "#             preds = torch.sigmoid(out).cpu().numpy()\n",
    "#             for i in range(out.shape[0]):\n",
    "#                 video, img_id = img_names[i].split(\"/\")\n",
    "#                 probs[video].append(preds[i].tolist())\n",
    "#                 targets[video].append(labels[i].tolist())\n",
    "#     data_x = []\n",
    "#     data_y = []\n",
    "#     for vid, score in probs.items():\n",
    "#         score = np.array(score)\n",
    "#         lbl = targets[vid]\n",
    "\n",
    "#         score = np.mean(score)\n",
    "#         lbl = np.mean(lbl)\n",
    "#         data_x.append(score)\n",
    "#         data_y.append(lbl)\n",
    "#     y = np.array(data_y)\n",
    "#     x = np.array(data_x)\n",
    "#     fake_idx = y > 0.1\n",
    "#     real_idx = y < 0.1\n",
    "#     fake_loss = log_loss(y[fake_idx], x[fake_idx], labels=[0, 1])\n",
    "#     real_loss = log_loss(y[real_idx], x[real_idx], labels=[0, 1])\n",
    "#     print(f\"{prefix}fake_loss\", fake_loss)\n",
    "#     print(f\"{prefix}real_loss\", real_loss)\n",
    "\n",
    "#     return (fake_loss + real_loss) / 2, probs, targets\n",
    "\n",
    "# # Define evaluation and validation functions\n",
    "# def evaluate_val(args, data_val, bce_best, model, snapshot_name, current_epoch, summary_writer):\n",
    "#     print(\"Test phase\")\n",
    "#     model = model.eval()\n",
    "\n",
    "#     bce, probs, targets = validate(model, data_loader=data_val)\n",
    "#     if args.local_rank == 0:\n",
    "#         summary_writer.add_scalar('val/bce', float(bce), global_step=current_epoch)\n",
    "#         if bce < bce_best:\n",
    "#             print(f\"Epoch {current_epoch} improved from {bce_best} to {bce}\")\n",
    "#             if args.output_dir is not None:\n",
    "#                 torch.save({\n",
    "#                     'epoch': current_epoch + 1,\n",
    "#                     'state_dict': model.state_dict(),\n",
    "#                     'bce_best': bce,\n",
    "#                 }, args.output_dir + snapshot_name + \"_best_dice\")\n",
    "#             bce_best = bce\n",
    "#             with open(f\"predictions_{args.fold}.json\", \"w\") as f:\n",
    "#                 json.dump({\"probs\": probs, \"targets\": targets}, f)\n",
    "#         torch.save({\n",
    "#             'epoch': current_epoch + 1,\n",
    "#             'state_dict': model.state_dict(),\n",
    "#             'bce_best': bce_best,\n",
    "#         }, args)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MyEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
