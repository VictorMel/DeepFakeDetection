{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Setting Up Environment and Dependencies\n",
    "Ensure you have the necessary libraries installed. You may need to install additional packages like TensorFlow (for AMD GPUs) or other deep learning frameworks suitable for your GPU setup.\n",
    "\n",
    "2. Data Loading\n",
    "First, you've already inspected your data, which consists of videos in mp4 format and associated metadata in a JSON file. You will need to prepare data loaders to efficiently load and preprocess these videos.\n",
    "\n",
    "Data Loader for Videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcv2\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Sequence\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from tensorflow.keras.utils import Sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VideoLoader(Sequence):\n",
    "    def __init__(self, video_files, labels, data_folder, batch_size=32, frame_size=(128, 128)):\n",
    "        self.video_files = video_files\n",
    "        self.labels = labels\n",
    "        self.data_folder = data_folder\n",
    "        self.batch_size = batch_size\n",
    "        self.frame_size = frame_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.video_files) / float(self.batch_size)))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        batch_files = self.video_files[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        batch_labels = self.labels[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "\n",
    "        X = np.zeros((len(batch_files), *self.frame_size, 3))\n",
    "        y = np.array(batch_labels)\n",
    "\n",
    "        for i, file in enumerate(batch_files):\n",
    "            cap = cv2.VideoCapture(os.path.join(self.data_folder, file))\n",
    "            ret, frame = cap.read()\n",
    "            cap.release()\n",
    "            frame = cv2.resize(frame, self.frame_size)\n",
    "            X[i] = frame / 255.0  # normalize\n",
    "\n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Building a Basic Neural Network Model\n",
    "For simplicity, let's construct a basic Convolutional Neural Network (CNN) using TensorFlow/Keras:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "\n",
    "def create_model(input_shape):\n",
    "    model = Sequential([\n",
    "        Conv2D(16, (3, 3), activation='relu', input_shape=input_shape),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Conv2D(32, (3, 3), activation='relu'),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Conv2D(64, (3, 3), activation='relu'),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Flatten(),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Training and Evaluation\n",
    "Now, let's put everything together to train and evaluate the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you have loaded your metadata and prepared video files\n",
    "train_video_files = meta_train_df.index.tolist()\n",
    "train_labels = (meta_train_df['label'] == 'FAKE').astype(int).values\n",
    "\n",
    "# Example usage:\n",
    "train_loader = VideoLoader(train_video_files, train_labels, DATA_FOLDER, batch_size=32)\n",
    "\n",
    "# Define input shape based on your frame size\n",
    "input_shape = (*train_loader.frame_size, 3)\n",
    "\n",
    "# Create model\n",
    "model = create_model(input_shape)\n",
    "\n",
    "# Train model\n",
    "model.fit(train_loader, epochs=10)\n",
    "\n",
    "# Evaluate model\n",
    "# Example: validation_loader = VideoLoader(validation_video_files, validation_labels, DATA_FOLDER, batch_size=32)\n",
    "# loss, accuracy = model.evaluate(validation_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
