{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load packages\n",
    "\n",
    "import os\n",
    "from os import path\n",
    "from typing import Optional\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# Deep Learning\n",
    "import torch\n",
    "import torch.nn            as nn\n",
    "import torch.nn.functional as F\n",
    "import torchinfo\n",
    "import cv2 as cv\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "\n",
    "MY_NAME_IS = 'Nitzan'\n",
    "\n",
    "TRAIN_PARTS = [0, 1, 2, 3]\n",
    "TEST_PARTS = [4]\n",
    "\n",
    "DOWN_FPS = 10\n",
    "FRAME_SCALE = 20\n",
    "GRAYCOLOR = False\n",
    "\n",
    "BATCH_SIZE = 3\n",
    "EPOCH_NUM = 1\n",
    "\n",
    "################################################################################################\n",
    "\n",
    "DATA_FOLDER_DICT = {\n",
    "    'Victor': ['E:\\DeepFakeDetection\\dfdc_train_all','E:\\DeepFakeDetection\\smalldata'],\n",
    "    'Nitzan': ['D:\\dfdc','D:\\dfdc_small5'],\n",
    "    'Netanel':['F:\\input','F:\\input']}\n",
    "BIG_DATA_FOLDER = DATA_FOLDER_DICT[MY_NAME_IS][0]\n",
    "SMALL_DATA_FOLDER = DATA_FOLDER_DICT[MY_NAME_IS][1]\n",
    "\n",
    "TORCH_DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'The chosen device: {TORCH_DEVICE}')\n",
    "\n",
    "SMALLFILE_EXT = 'tns'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and concat all JSON files\n",
    "\n",
    "meta_df = pd.DataFrame()\n",
    "metadata_glob = glob.iglob('**/metadata.json', recursive=True, root_dir=BIG_DATA_FOLDER)\n",
    "ii = 0\n",
    "for metadata in metadata_glob:\n",
    "    metadata_path = path.join(BIG_DATA_FOLDER, metadata)\n",
    "    dir_path = os.path.dirname(os.path.realpath(metadata_path))\n",
    "    part_df = pd.read_json(metadata_path).T\n",
    "    part_df['part'] = ii\n",
    "    part_df['bigdata_path'] = dir_path\n",
    "    part_df['smalldata_path'] = f\"{SMALL_DATA_FOLDER}\\{ii}\"\n",
    "    #part_df['filename'] = part_df.index\n",
    "    meta_df = pd.concat([meta_df, part_df])\n",
    "    ii += 1\n",
    "\n",
    "display(meta_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split Data, Take part of data\n",
    "\n",
    "metadata_train_df = meta_df[meta_df['part'].isin(TRAIN_PARTS)].copy()\n",
    "metadata_test_df = meta_df[meta_df['part'].isin(TEST_PARTS)].copy()\n",
    "metadata_test_df['split'] = 'test'\n",
    "metadata_df = pd.concat((metadata_train_df,metadata_test_df))\n",
    "display(metadata_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# New preprocess function. Performs:\n",
    "# - downscales fps to the given value, \n",
    "# - resizes to the given width (preserving aspect ratio)\n",
    "# - converts to tensor\n",
    "\n",
    "def preprocess_video(filepath: str, output_fps: int, resize_height: int, crop_size: int):\n",
    "  cap = cv.VideoCapture(filepath)\n",
    "  fps = cap.get(cv.CAP_PROP_FPS)\n",
    "  frame_count = int(cap.get(cv.CAP_PROP_FRAME_COUNT))\n",
    "  fps_step = round(fps / output_fps)\n",
    "\n",
    "  width: int = int(cap.get(cv.CAP_PROP_FRAME_WIDTH))\n",
    "  height: int = int(cap.get(cv.CAP_PROP_FRAME_HEIGHT))\n",
    "  aspect_ratio = width / height\n",
    "  if (height > width):\n",
    "    return None\n",
    "\n",
    "  if not cap.isOpened():\n",
    "    raise Exception(\"Error opening video file\")\n",
    "  \n",
    "  new_width = int(resize_height * aspect_ratio)\n",
    "  new_height = resize_height\n",
    "  new_frame_count = frame_count // fps_step\n",
    "\n",
    "  video = torch.empty((new_frame_count, crop_size, crop_size, 3), dtype=torch.uint8)\n",
    "\n",
    "  for index in range(new_frame_count * fps_step):\n",
    "    ok, frame = cap.read()\n",
    "    if not ok:\n",
    "      print(index, frame_count, new_frame_count*fps_step)\n",
    "      raise Exception('Error reading frame')\n",
    "\n",
    "    if index % fps_step != 0:\n",
    "      continue\n",
    "    scaled_index = index // fps_step\n",
    "\n",
    "    frame = cv.cvtColor(frame, cv.COLOR_BGR2RGB)\n",
    "\n",
    "    # Resize frame, video is in HWC format\n",
    "    frame = cv.resize(frame, (new_height, new_width), interpolation=cv.INTER_AREA)\n",
    "\n",
    "    # Center crop frame\n",
    "    x = (new_width - crop_size) // 2\n",
    "    y = (new_height - crop_size) // 2\n",
    "    frame = frame[x:x+crop_size, y:y+crop_size, :] \n",
    "\n",
    "    video[scaled_index] = torch.tensor(frame, dtype=torch.uint8)\n",
    "\n",
    "  cap.release()\n",
    "  return video\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_file_index = 0\n",
    "file_count = metadata_df.shape[0]\n",
    "\n",
    "output_fps = 10\n",
    "resize_width = 128\n",
    "crop_size = 112\n",
    "\n",
    "cv.setNumThreads(os.cpu_count() - 1)\n",
    "\n",
    "pbar = tqdm(\n",
    "  metadata_df[start_file_index:].iterrows(), \n",
    "  total=file_count-start_file_index, \n",
    "  desc=\"Preprocessing videos\"\n",
    "  )\n",
    "\n",
    "for file_name, row in pbar:\n",
    "  try:\n",
    "    original_file_path = path.join(row['bigdata_path'], file_name)\n",
    "    base_name, _ = path.splitext(file_name)\n",
    "    target_file_path = path.join(row['smalldata_path'], f\"{base_name}.{SMALLFILE_EXT}\")\n",
    "    \n",
    "    video = preprocess_video(original_file_path, output_fps, resize_width, crop_size)\n",
    "    if video is None:\n",
    "      continue\n",
    "    # print(video)\n",
    "    # print(f'video shape: {video.shape}, dtype: {video.dtype}, size in memory: {video.element_size() * video.nelement() / (1024**2):.2f}mb')\n",
    "\n",
    "    output_dir = row['smalldata_path']\n",
    "    if not path.exists(output_dir):\n",
    "      os.makedirs(output_dir)\n",
    "    torch.save(video, target_file_path)\n",
    "  except Exception as e:\n",
    "    print(f\"Error: {e}\")\n",
    "    continue\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
