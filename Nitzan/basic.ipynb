{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.io import read_video\n",
    "from torch import nn\n",
    "import json\n",
    "from os import path\n",
    "from typing import Self, TypedDict, Union, Optional, Literal, List, Tuple\n",
    "import time\n",
    "\n",
    "DATA_PATH = 'D:\\dfdc'\n",
    "NUM_PARTS = 50\n",
    "Split = Union[Literal['train'], Literal['validation']]\n",
    "Label = Union[Literal[0], Literal[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class FileMetadata(TypedDict):\n",
    "  path: str\n",
    "  label: Union[Literal['REAL'], Literal['FAKE']]\n",
    "  original: Optional[str]\n",
    "\n",
    "class VideoDataset(Dataset):\n",
    "  def __get_part_directory(self: Self, index: int) -> str:\n",
    "    return path.join(self.root_path, f'dfdc_train_part_{index}')\n",
    "\n",
    "  def __init__(self: Self, root_path: str, split: Split):\n",
    "    self.root_path = root_path\n",
    "\n",
    "    # Init metadata\n",
    "    self.metadata: List[FileMetadata] = []\n",
    "    for i in range(NUM_PARTS):\n",
    "      print(f'reading part {i} metadata...')\n",
    "      start = time.time()\n",
    "      dir_path = self.__get_part_directory(i)\n",
    "      metadata_path = path.join(dir_path, 'metadata.json')\n",
    "      metadata = json.load(open(metadata_path))\n",
    "      post_load = time.time()\n",
    "      print(f'loading json took {1_000*(post_load - start):.2f}ms')\n",
    "      for k, data in metadata.items():\n",
    "        if data['split'] != split:\n",
    "          continue\n",
    "\n",
    "        video_path = path.join(dir_path, k)\n",
    "        data['path'] = video_path\n",
    "        del data['split']\n",
    "\n",
    "        self.metadata.append(data)\n",
    "      \n",
    "      post_parse = time.time()\n",
    "      print(f'parsing json took {1_000*(post_parse - post_load):.2f}ms')\n",
    "\n",
    "\n",
    "  def __getitem__(self: Self, index: int) -> Tuple[torch.Tensor, Label]:\n",
    "    metadata = self.metadata[index]\n",
    "    # How do we handle the audio as well?\n",
    "    video, audio, _ = read_video(metadata['path'], pts_unit='sec')\n",
    "    label = 1 if metadata['label'] == 'FAKE' else 0\n",
    "\n",
    "    return video, label\n",
    "  \n",
    "  def __len__(self: Self):\n",
    "    return len(self.metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading part 0 metadata...\n",
      "loading json took 3.00ms\n",
      "parsing json took 4.00ms\n",
      "reading part 1 metadata...\n",
      "loading json took 2.00ms\n",
      "parsing json took 4.00ms\n",
      "reading part 2 metadata...\n",
      "loading json took 10.00ms\n",
      "parsing json took 4.00ms\n",
      "reading part 3 metadata...\n",
      "loading json took 3.00ms\n",
      "parsing json took 3.00ms\n",
      "reading part 4 metadata...\n",
      "loading json took 2.00ms\n",
      "parsing json took 4.00ms\n",
      "reading part 5 metadata...\n",
      "loading json took 2.00ms\n",
      "parsing json took 6.00ms\n",
      "reading part 6 metadata...\n",
      "loading json took 3.00ms\n",
      "parsing json took 7.00ms\n",
      "reading part 7 metadata...\n",
      "loading json took 3.00ms\n",
      "parsing json took 6.00ms\n",
      "reading part 8 metadata...\n",
      "loading json took 2.08ms\n",
      "parsing json took 3.92ms\n",
      "reading part 9 metadata...\n",
      "loading json took 2.00ms\n",
      "parsing json took 4.00ms\n",
      "reading part 10 metadata...\n",
      "loading json took 3.00ms\n",
      "parsing json took 7.00ms\n",
      "reading part 11 metadata...\n",
      "loading json took 2.00ms\n",
      "parsing json took 5.00ms\n",
      "reading part 12 metadata...\n",
      "loading json took 3.08ms\n",
      "parsing json took 4.92ms\n",
      "reading part 13 metadata...\n",
      "loading json took 4.00ms\n",
      "parsing json took 8.00ms\n",
      "reading part 14 metadata...\n",
      "loading json took 2.00ms\n",
      "parsing json took 5.00ms\n",
      "reading part 15 metadata...\n",
      "loading json took 3.00ms\n",
      "parsing json took 5.00ms\n",
      "reading part 16 metadata...\n",
      "loading json took 3.00ms\n",
      "parsing json took 4.00ms\n",
      "reading part 17 metadata...\n",
      "loading json took 7.00ms\n",
      "parsing json took 6.00ms\n",
      "reading part 18 metadata...\n",
      "loading json took 2.00ms\n",
      "parsing json took 6.07ms\n",
      "reading part 19 metadata...\n",
      "loading json took 2.93ms\n",
      "parsing json took 7.13ms\n",
      "reading part 20 metadata...\n",
      "loading json took 1.87ms\n",
      "parsing json took 5.00ms\n",
      "reading part 21 metadata...\n",
      "loading json took 2.00ms\n",
      "parsing json took 5.00ms\n",
      "reading part 22 metadata...\n",
      "loading json took 2.00ms\n",
      "parsing json took 5.00ms\n",
      "reading part 23 metadata...\n",
      "loading json took 2.00ms\n",
      "parsing json took 5.00ms\n",
      "reading part 24 metadata...\n",
      "loading json took 3.00ms\n",
      "parsing json took 6.00ms\n",
      "reading part 25 metadata...\n",
      "loading json took 3.00ms\n",
      "parsing json took 6.00ms\n",
      "reading part 26 metadata...\n",
      "loading json took 2.00ms\n",
      "parsing json took 5.00ms\n",
      "reading part 27 metadata...\n",
      "loading json took 3.00ms\n",
      "parsing json took 6.00ms\n",
      "reading part 28 metadata...\n",
      "loading json took 3.00ms\n",
      "parsing json took 4.00ms\n",
      "reading part 29 metadata...\n",
      "loading json took 3.00ms\n",
      "parsing json took 6.00ms\n",
      "reading part 30 metadata...\n",
      "loading json took 2.00ms\n",
      "parsing json took 5.00ms\n",
      "reading part 31 metadata...\n",
      "loading json took 2.00ms\n",
      "parsing json took 6.01ms\n",
      "reading part 32 metadata...\n",
      "loading json took 5.00ms\n",
      "parsing json took 6.00ms\n",
      "reading part 33 metadata...\n",
      "loading json took 5.00ms\n",
      "parsing json took 6.00ms\n",
      "reading part 34 metadata...\n",
      "loading json took 3.00ms\n",
      "parsing json took 5.00ms\n",
      "reading part 35 metadata...\n",
      "loading json took 3.00ms\n",
      "parsing json took 5.00ms\n",
      "reading part 36 metadata...\n",
      "loading json took 3.00ms\n",
      "parsing json took 5.00ms\n",
      "reading part 37 metadata...\n",
      "loading json took 3.00ms\n",
      "parsing json took 5.00ms\n",
      "reading part 38 metadata...\n",
      "loading json took 3.00ms\n",
      "parsing json took 5.00ms\n",
      "reading part 39 metadata...\n",
      "loading json took 2.00ms\n",
      "parsing json took 6.00ms\n",
      "reading part 40 metadata...\n",
      "loading json took 2.00ms\n",
      "parsing json took 5.07ms\n",
      "reading part 41 metadata...\n",
      "loading json took 2.93ms\n",
      "parsing json took 4.00ms\n",
      "reading part 42 metadata...\n",
      "loading json took 2.00ms\n",
      "parsing json took 5.00ms\n",
      "reading part 43 metadata...\n",
      "loading json took 2.00ms\n",
      "parsing json took 6.00ms\n",
      "reading part 44 metadata...\n",
      "loading json took 3.00ms\n",
      "parsing json took 5.06ms\n",
      "reading part 45 metadata...\n",
      "loading json took 2.00ms\n",
      "parsing json took 5.00ms\n",
      "reading part 46 metadata...\n",
      "loading json took 2.00ms\n",
      "parsing json took 5.00ms\n",
      "reading part 47 metadata...\n",
      "loading json took 2.00ms\n",
      "parsing json took 7.00ms\n",
      "reading part 48 metadata...\n",
      "loading json took 3.00ms\n",
      "parsing json took 6.00ms\n",
      "reading part 49 metadata...\n",
      "loading json took 3.00ms\n",
      "parsing json took 7.00ms\n"
     ]
    }
   ],
   "source": [
    "# Test the VideoDataset\n",
    "loader = DataLoader(VideoDataset(DATA_PATH, 'train'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1])\n"
     ]
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Get some images & labels from the data loader\n",
    "\n",
    "data, label = next(iter(loader))\n",
    "\n",
    "# data dimensions are BxTxCxHxW\n",
    "\n",
    "fig = plt.figure(figsize=(12, 6))\n",
    "fig.add_subplot(1, 3, 1)\n",
    "plt.imshow(data[0][0])\n",
    "fig.add_subplot(1, 3, 2)\n",
    "plt.imshow(data[0][100])\n",
    "fig.add_subplot(1, 3, 3)\n",
    "plt.imshow(data[0][-1])\n",
    "\n",
    "print(label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "device = (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Conv3d(3, 16, kernel_size=3, stride=1, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool3d(2),\n",
    "    nn.Conv3d(16, 32, kernel_size=3, stride=1, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool3d(2),\n",
    "    nn.Conv3d(32, 64, kernel_size=3, stride=1, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool3d(2),\n",
    "    nn.Conv3d(64, 128, kernel_size=3, stride=1, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool3d(2),\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(128, 2),\n",
    "    nn.Softmax(dim=1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading part 0 metadata...\n",
      "loading json took 1.00ms\n",
      "parsing json took 3.00ms\n",
      "reading part 1 metadata...\n",
      "loading json took 1.00ms\n",
      "parsing json took 4.00ms\n",
      "reading part 2 metadata...\n",
      "loading json took 2.00ms\n",
      "parsing json took 3.00ms\n",
      "reading part 3 metadata...\n",
      "loading json took 3.00ms\n",
      "parsing json took 2.00ms\n",
      "reading part 4 metadata...\n",
      "loading json took 2.00ms\n",
      "parsing json took 3.00ms\n",
      "reading part 5 metadata...\n",
      "loading json took 3.00ms\n",
      "parsing json took 6.00ms\n",
      "reading part 6 metadata...\n",
      "loading json took 3.00ms\n",
      "parsing json took 12.00ms\n",
      "reading part 7 metadata...\n",
      "loading json took 4.00ms\n",
      "parsing json took 6.00ms\n",
      "reading part 8 metadata...\n",
      "loading json took 2.00ms\n",
      "parsing json took 4.00ms\n",
      "reading part 9 metadata...\n",
      "loading json took 2.00ms\n",
      "parsing json took 4.00ms\n",
      "reading part 10 metadata...\n",
      "loading json took 3.00ms\n",
      "parsing json took 7.00ms\n",
      "reading part 11 metadata...\n",
      "loading json took 2.00ms\n",
      "parsing json took 4.00ms\n",
      "reading part 12 metadata...\n",
      "loading json took 2.00ms\n",
      "parsing json took 5.00ms\n",
      "reading part 13 metadata...\n",
      "loading json took 3.00ms\n",
      "parsing json took 7.00ms\n",
      "reading part 14 metadata...\n",
      "loading json took 3.00ms\n",
      "parsing json took 4.00ms\n",
      "reading part 15 metadata...\n",
      "loading json took 2.00ms\n",
      "parsing json took 5.00ms\n",
      "reading part 16 metadata...\n",
      "loading json took 2.00ms\n",
      "parsing json took 4.00ms\n",
      "reading part 17 metadata...\n",
      "loading json took 1.00ms\n",
      "parsing json took 5.00ms\n",
      "reading part 18 metadata...\n",
      "loading json took 3.00ms\n",
      "parsing json took 5.00ms\n",
      "reading part 19 metadata...\n",
      "loading json took 2.00ms\n",
      "parsing json took 6.00ms\n",
      "reading part 20 metadata...\n",
      "loading json took 2.00ms\n",
      "parsing json took 5.00ms\n",
      "reading part 21 metadata...\n",
      "loading json took 2.00ms\n",
      "parsing json took 4.00ms\n",
      "reading part 22 metadata...\n",
      "loading json took 2.00ms\n",
      "parsing json took 5.00ms\n",
      "reading part 23 metadata...\n",
      "loading json took 2.03ms\n",
      "parsing json took 4.00ms\n",
      "reading part 24 metadata...\n",
      "loading json took 2.96ms\n",
      "parsing json took 5.00ms\n",
      "reading part 25 metadata...\n",
      "loading json took 2.00ms\n",
      "parsing json took 5.00ms\n",
      "reading part 26 metadata...\n",
      "loading json took 2.00ms\n",
      "parsing json took 5.00ms\n",
      "reading part 27 metadata...\n",
      "loading json took 3.00ms\n",
      "parsing json took 5.03ms\n",
      "reading part 28 metadata...\n",
      "loading json took 2.00ms\n",
      "parsing json took 3.97ms\n",
      "reading part 29 metadata...\n",
      "loading json took 2.00ms\n",
      "parsing json took 5.00ms\n",
      "reading part 30 metadata...\n",
      "loading json took 2.00ms\n",
      "parsing json took 4.00ms\n",
      "reading part 31 metadata...\n",
      "loading json took 2.00ms\n",
      "parsing json took 5.00ms\n",
      "reading part 32 metadata...\n",
      "loading json took 2.00ms\n",
      "parsing json took 5.00ms\n",
      "reading part 33 metadata...\n",
      "loading json took 2.00ms\n",
      "parsing json took 4.00ms\n",
      "reading part 34 metadata...\n",
      "loading json took 2.00ms\n",
      "parsing json took 6.00ms\n",
      "reading part 35 metadata...\n",
      "loading json took 2.00ms\n",
      "parsing json took 5.00ms\n",
      "reading part 36 metadata...\n",
      "loading json took 2.00ms\n",
      "parsing json took 4.00ms\n",
      "reading part 37 metadata...\n",
      "loading json took 2.00ms\n",
      "parsing json took 5.00ms\n",
      "reading part 38 metadata...\n",
      "loading json took 2.00ms\n",
      "parsing json took 5.03ms\n",
      "reading part 39 metadata...\n",
      "loading json took 2.00ms\n",
      "parsing json took 4.97ms\n",
      "reading part 40 metadata...\n",
      "loading json took 2.00ms\n",
      "parsing json took 5.00ms\n",
      "reading part 41 metadata...\n",
      "loading json took 1.00ms\n",
      "parsing json took 5.00ms\n",
      "reading part 42 metadata...\n",
      "loading json took 2.00ms\n",
      "parsing json took 5.00ms\n",
      "reading part 43 metadata...\n",
      "loading json took 2.00ms\n",
      "parsing json took 5.00ms\n",
      "reading part 44 metadata...\n",
      "loading json took 2.00ms\n",
      "parsing json took 5.00ms\n",
      "reading part 45 metadata...\n",
      "loading json took 2.00ms\n",
      "parsing json took 5.00ms\n",
      "reading part 46 metadata...\n",
      "loading json took 1.00ms\n",
      "parsing json took 5.00ms\n",
      "reading part 47 metadata...\n",
      "loading json took 2.00ms\n",
      "parsing json took 5.00ms\n",
      "reading part 48 metadata...\n",
      "loading json took 2.00ms\n",
      "parsing json took 5.00ms\n",
      "reading part 49 metadata...\n",
      "loading json took 2.00ms\n",
      "parsing json took 7.00ms\n",
      "reading part 0 metadata...\n",
      "loading json took 1.00ms\n",
      "parsing json took 0.00ms\n",
      "reading part 1 metadata...\n",
      "loading json took 2.00ms\n",
      "parsing json took 0.00ms\n",
      "reading part 2 metadata...\n",
      "loading json took 1.00ms\n",
      "parsing json took 0.00ms\n",
      "reading part 3 metadata...\n",
      "loading json took 1.00ms\n",
      "parsing json took 0.00ms\n",
      "reading part 4 metadata...\n",
      "loading json took 2.00ms\n",
      "parsing json took 0.00ms\n",
      "reading part 5 metadata...\n",
      "loading json took 2.00ms\n",
      "parsing json took 0.00ms\n",
      "reading part 6 metadata...\n",
      "loading json took 3.00ms\n",
      "parsing json took 0.00ms\n",
      "reading part 7 metadata...\n",
      "loading json took 2.00ms\n",
      "parsing json took 0.00ms\n",
      "reading part 8 metadata...\n",
      "loading json took 2.00ms\n",
      "parsing json took 0.00ms\n",
      "reading part 9 metadata...\n",
      "loading json took 1.00ms\n",
      "parsing json took 0.00ms\n",
      "reading part 10 metadata...\n",
      "loading json took 3.00ms\n",
      "parsing json took 0.00ms\n",
      "reading part 11 metadata...\n",
      "loading json took 1.00ms\n",
      "parsing json took 0.00ms\n",
      "reading part 12 metadata...\n",
      "loading json took 2.00ms\n",
      "parsing json took 0.00ms\n",
      "reading part 13 metadata...\n",
      "loading json took 3.00ms\n",
      "parsing json took 0.00ms\n",
      "reading part 14 metadata...\n",
      "loading json took 2.00ms\n",
      "parsing json took 1.00ms\n",
      "reading part 15 metadata...\n",
      "loading json took 1.00ms\n",
      "parsing json took 1.00ms\n",
      "reading part 16 metadata...\n",
      "loading json took 1.00ms\n",
      "parsing json took 0.00ms\n",
      "reading part 17 metadata...\n",
      "loading json took 2.00ms\n",
      "parsing json took 0.00ms\n",
      "reading part 18 metadata...\n",
      "loading json took 2.00ms\n",
      "parsing json took 0.00ms\n",
      "reading part 19 metadata...\n",
      "loading json took 2.00ms\n",
      "parsing json took 0.00ms\n",
      "reading part 20 metadata...\n",
      "loading json took 1.00ms\n",
      "parsing json took 0.00ms\n",
      "reading part 21 metadata...\n",
      "loading json took 2.00ms\n",
      "parsing json took 0.00ms\n",
      "reading part 22 metadata...\n",
      "loading json took 2.00ms\n",
      "parsing json took 0.00ms\n",
      "reading part 23 metadata...\n",
      "loading json took 2.00ms\n",
      "parsing json took 0.00ms\n",
      "reading part 24 metadata...\n",
      "loading json took 2.00ms\n",
      "parsing json took 0.00ms\n",
      "reading part 25 metadata...\n",
      "loading json took 2.00ms\n",
      "parsing json took 0.00ms\n",
      "reading part 26 metadata...\n",
      "loading json took 1.00ms\n",
      "parsing json took 0.00ms\n",
      "reading part 27 metadata...\n",
      "loading json took 2.00ms\n",
      "parsing json took 0.00ms\n",
      "reading part 28 metadata...\n",
      "loading json took 3.00ms\n",
      "parsing json took 0.00ms\n",
      "reading part 29 metadata...\n",
      "loading json took 2.00ms\n",
      "parsing json took 0.00ms\n",
      "reading part 30 metadata...\n",
      "loading json took 2.00ms\n",
      "parsing json took 0.00ms\n",
      "reading part 31 metadata...\n",
      "loading json took 2.00ms\n",
      "parsing json took 0.00ms\n",
      "reading part 32 metadata...\n",
      "loading json took 2.00ms\n",
      "parsing json took 0.00ms\n",
      "reading part 33 metadata...\n",
      "loading json took 2.00ms\n",
      "parsing json took 0.00ms\n",
      "reading part 34 metadata...\n",
      "loading json took 2.00ms\n",
      "parsing json took 0.00ms\n",
      "reading part 35 metadata...\n",
      "loading json took 2.00ms\n",
      "parsing json took 0.00ms\n",
      "reading part 36 metadata...\n",
      "loading json took 2.00ms\n",
      "parsing json took 0.00ms\n",
      "reading part 37 metadata...\n",
      "loading json took 2.00ms\n",
      "parsing json took 0.00ms\n",
      "reading part 38 metadata...\n",
      "loading json took 2.00ms\n",
      "parsing json took 0.00ms\n",
      "reading part 39 metadata...\n",
      "loading json took 3.00ms\n",
      "parsing json took 0.00ms\n",
      "reading part 40 metadata...\n",
      "loading json took 2.00ms\n",
      "parsing json took 0.00ms\n",
      "reading part 41 metadata...\n",
      "loading json took 2.00ms\n",
      "parsing json took 1.00ms\n",
      "reading part 42 metadata...\n",
      "loading json took 2.00ms\n",
      "parsing json took 0.00ms\n",
      "reading part 43 metadata...\n",
      "loading json took 2.00ms\n",
      "parsing json took 0.00ms\n",
      "reading part 44 metadata...\n",
      "loading json took 2.00ms\n",
      "parsing json took 0.00ms\n",
      "reading part 45 metadata...\n",
      "loading json took 2.00ms\n",
      "parsing json took 0.00ms\n",
      "reading part 46 metadata...\n",
      "loading json took 3.00ms\n",
      "parsing json took 0.00ms\n",
      "reading part 47 metadata...\n",
      "loading json took 2.00ms\n",
      "parsing json took 0.00ms\n",
      "reading part 48 metadata...\n",
      "loading json took 3.00ms\n",
      "parsing json took 0.00ms\n",
      "reading part 49 metadata...\n",
      "loading json took 3.00ms\n",
      "parsing json took 0.00ms\n"
     ]
    }
   ],
   "source": [
    "train_dl = DataLoader(VideoDataset(DATA_PATH, 'train'))\n",
    "validation_dl = DataLoader(VideoDataset(DATA_PATH, 'validation'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Input type (unsigned char) and bias type (float) should be the same",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m score_fn \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mSoftmax(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m      6\u001b[0m num_epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m\n\u001b[1;32m----> 8\u001b[0m train_model \u001b[38;5;241m=\u001b[39m \u001b[43mTrainModel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_dl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscore_fn\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Nitzan\\Documents\\Projects\\DeepFakeDetection\\Nitzan\\train_model.py:130\u001b[0m, in \u001b[0;36mTrainModel\u001b[1;34m(oModel, dlTrain, dlVal, oOpt, numEpoch, hL, hS, oSch)\u001b[0m\n\u001b[0;32m    128\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m ii \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(numEpoch):\n\u001b[0;32m    129\u001b[0m     startTime           \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m--> 130\u001b[0m     trainLoss, trainScr \u001b[38;5;241m=\u001b[39m \u001b[43mRunEpoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43moModel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdlTrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhL\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moOpt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopMode\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mNNMode\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTRAIN\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m#<! Train\u001b[39;00m\n\u001b[0;32m    131\u001b[0m     valLoss,   valScr   \u001b[38;5;241m=\u001b[39m RunEpoch(oModel, dlVal, hL, hS, oOpt, opMode \u001b[38;5;241m=\u001b[39m NNMode\u001b[38;5;241m.\u001b[39mINFERENCE) \u001b[38;5;66;03m#<! Score Validation\u001b[39;00m\n\u001b[0;32m    132\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m oSch \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    133\u001b[0m         \u001b[38;5;66;03m# Adjusting the scheduler on Epoch level\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Nitzan\\Documents\\Projects\\DeepFakeDetection\\Nitzan\\train_model.py:60\u001b[0m, in \u001b[0;36mRunEpoch\u001b[1;34m(oModel, dlData, hL, hS, oOpt, opMode)\u001b[0m\n\u001b[0;32m     56\u001b[0m batchSize \u001b[38;5;241m=\u001b[39m mX\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m opMode \u001b[38;5;241m==\u001b[39m NNMode\u001b[38;5;241m.\u001b[39mTRAIN:\n\u001b[0;32m     59\u001b[0m     \u001b[38;5;66;03m# Forward\u001b[39;00m\n\u001b[1;32m---> 60\u001b[0m     mZ      \u001b[38;5;241m=\u001b[39m \u001b[43moModel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmX\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m#<! Model output\u001b[39;00m\n\u001b[0;32m     61\u001b[0m     valLoss \u001b[38;5;241m=\u001b[39m hL(mZ, vY) \u001b[38;5;66;03m#<! Loss\u001b[39;00m\n\u001b[0;32m     63\u001b[0m     \u001b[38;5;66;03m# Backward\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Nitzan\\miniconda3\\envs\\DL_env\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Nitzan\\miniconda3\\envs\\DL_env\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Nitzan\\miniconda3\\envs\\DL_env\\Lib\\site-packages\\torch\\nn\\modules\\container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\Nitzan\\miniconda3\\envs\\DL_env\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Nitzan\\miniconda3\\envs\\DL_env\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Nitzan\\miniconda3\\envs\\DL_env\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:610\u001b[0m, in \u001b[0;36mConv3d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    609\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 610\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Nitzan\\miniconda3\\envs\\DL_env\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:605\u001b[0m, in \u001b[0;36mConv3d._conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    593\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    594\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv3d(\n\u001b[0;32m    595\u001b[0m         F\u001b[38;5;241m.\u001b[39mpad(\n\u001b[0;32m    596\u001b[0m             \u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    603\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups,\n\u001b[0;32m    604\u001b[0m     )\n\u001b[1;32m--> 605\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv3d\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    606\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\n\u001b[0;32m    607\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Input type (unsigned char) and bias type (float) should be the same"
     ]
    }
   ],
   "source": [
    "from train_model import TrainModel\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "score_fn = nn.Softmax(dim=1)\n",
    "num_epochs = 10\n",
    "\n",
    "train_model = TrainModel(model, train_dl, validation_dl, optimizer, num_epochs, loss_fn, score_fn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
